{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation 4 with dynamic aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulating the WTSN setting\n",
    "\n",
    "Authors: Milind Kumar Vaddiraju, ChatGPT, Copilot\n",
    "\"\"\"\n",
    "\n",
    "# Necessary imports\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import json\n",
    "# %matplotlib inlinez\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from network_classes import *\n",
    "from utils import *\n",
    "from schedules import *\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_filename = \"../wireless_parameters/wireless_parameters_DL_MU_964B_80MHz.json\"\n",
    "with open(parameters_filename, 'r') as f:\n",
    "    parameters = json.load(f)\n",
    "print(parameters[\"setting 6\"][\"delivery_latency\"][9])\n",
    "\n",
    "delivery_latency_OFDMA = {}\n",
    "# TODO: Check MCS numbers\n",
    "delivery_latency_OFDMA[\"MCS 2\"] = [1172.8, 1921.6, 2684.8, 3433.6, 4182.4, 4931.2, 5694.4, 6443.2, 7192]\n",
    "delivery_latency_OFDMA[\"MCS 3\"] = [985.6, 1547.2, 2108.8, 2670.4, 3246.4, 3808, 4369.6, 4931.2, 5507.2]\n",
    "delivery_latency_OFDMA[\"MCS 4\"] = [798.4, 1172.8, 1547.2, 1921.6, 2296, 2670.4, 3059.2, 3433.6, 3808]\n",
    "delivery_latency_OFDMA[\"MCS 6\"] = [668.8, 913.6, 1172.8, 1417.6, 1676.8, 1921.6, 2180.8, 2425.6, \\\n",
    "                                   2670.4, 2929.6, 3174.4, 3433.6, 3678.4, 3937.6, 4182.4, 4427.2, \\\n",
    "                                   4686.4, 4931.2, 5190.4, 5435.2, 5694.4, 5939.2, 6184, 6443.2, \\\n",
    "                                   6688, 6947.2, 7192, 7451.2, 7696, 7940.8, 8200, 8444.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the simulation parameters\n",
    "\n",
    "results_directory_simulation = \"../results/simulation_4/\"\n",
    "config_file = \"No config file\"\n",
    "\n",
    "setting_reserved = \"setting 0\"\n",
    "setting_contention = \"setting 6\"\n",
    "payload_size = {\"reserved\": parameters[setting_reserved][\"payload_size\"]*parameters[setting_reserved][\"aggregation\"], \n",
    "                \"contention\": parameters[setting_contention][\"payload_size\"]*parameters[setting_contention][\"aggregation\"]}\n",
    "delivery_latency = {\"reserved\": parameters[setting_reserved][\"delivery_latency\"],\n",
    "                    \"contention\": parameters[setting_contention][\"delivery_latency\"]}\n",
    "PER = {\"reserved\":  parameters[setting_reserved][\"PER\"], \n",
    "       \"contention\":  0}\n",
    "aggregation_limit = 104\n",
    "\n",
    "\n",
    "OFDMA_MCS = \"MCS 6\"\n",
    "OFDMA_delivery_latency = delivery_latency_OFDMA[OFDMA_MCS]\n",
    "OFDMA_PER = 0.3\n",
    "delivery_latency[\"OFDMA\"] = OFDMA_delivery_latency\n",
    "PER[\"OFDMA\"] = OFDMA_PER\n",
    "\n",
    "\n",
    "num_UEs = 20\n",
    "UE_names = [\"UE\" + str(i) for i in range(num_UEs)]\n",
    "UE_names = [\"UE\" + str(i) for i in range(int(num_UEs/2))] + [\"UE\" + str(i) + \"_shadow\" for i in range(int(num_UEs/2))]\n",
    "num_packets_per_ue = None  # Number of packets per UE for the whole period\n",
    "packet_sizes = [parameters[setting_reserved][\"payload_size\"]] # TODO: Both have same packet size, but what if they don't?\n",
    "priorities = [1]\n",
    "# lambda_range = np.logspace(-4.5, -3, 20)\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3, 10), np.logspace(-3, -2.2, 5)))\n",
    "# For 10 UEs\n",
    "# lambda_range = np.logspace(-4.5, -3.765, 15)\n",
    "# For aggregation 5\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3.72, 6), np.logspace(-3.61, -3.43, 9)))\n",
    "# For aggregation 10\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3.83, 5), np.logspace(-3.75, -3.35, 10)))\n",
    "lambda_range = np.concatenate((np.logspace(-4.5, -3.83, 5), np.logspace(-3.75, -2.5, 20))) # testing code speed\n",
    "# lambda_range = [lambda_range[-1]]\n",
    "# lambda_range = [3000/10**6]\n",
    "# For aggregation 2\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3.8, 5), np.logspace(-3.745, -3.4, 5)))\n",
    "# lambda_range = [lambda_range[-1]]\n",
    "# For 3 UEs\n",
    "# lambda_range = np.logspace(-4.5, -3.26, 15)\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3.43, 8), np.logspace(-3.34, -3.26, 7)))\n",
    "# lambda_range = [10**(-4.5)]\n",
    "# For 5 UEs\n",
    "# lambda_range = np.logspace(-4.5, -3.45, 10)\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3.56, 5), np.logspace(-3.5, -3.45, 5)))\n",
    "# lambda_range = [lambda_range[-1]]\n",
    "# For 1 UE\n",
    "# lambda_range = np.logspace(-4.5, -3.5, 10)\n",
    "lambda_original = copy.deepcopy(lambda_range)\n",
    "UE_arrival = [\"Poisson\"]*num_UEs\n",
    "UE_serve_mode = [\"Mode 4\"]*num_UEs\n",
    "num_iterations_arrival = 5\n",
    "CWmin = 15\n",
    "CWmax = 1023\n",
    "\n",
    "\n",
    "## Schedule parameters for reserved base schedule\n",
    "start_offset = 10 # microseconds\n",
    "end_time = 1.5*10**6 + start_offset # microseconds\n",
    "# schedule_config = {\"schedule_name\": \"schedule 5\",\n",
    "#                    \"qbv_window_size\": 1250,\n",
    "#                    \"num_UEs_together_qbv\": 1,\n",
    "#                    \"contention_window_size\": 3000,\n",
    "#                    \"num_UEs_together_contention\": 2}\n",
    "\n",
    "# schedule_config = {\"schedule_name\": \"grouped roundrobin\",\n",
    "#                    \"qbv_window_size\": 2500,\n",
    "#                    \"num_UEs_together\": 2,\n",
    "#                    \"offset\": 5}\n",
    "\n",
    "# schedule_config = {\"schedule_name\": \"shuffle roundrobin\",\n",
    "#                    \"qbv_window_size\": 800,\n",
    "#                    }\n",
    "\n",
    "# schedule_config = {\"schedule_name\": \"shuffle roundrobin\",\n",
    "#                               \"qbv_window_size\": 1500,\n",
    "#                               \"contention_window_size\": 1000,\n",
    "#                               \"contention_UE_indices\": [4,5,7]}\n",
    "\n",
    "# schedule_config = {\"schedule_name\": \"roundrobin\",\n",
    "#                      \"qbv_window_size\": 8700}\n",
    "                            \n",
    "\n",
    "# schedule_config = {\"schedule_name\": \"CSMA\"}\n",
    "\n",
    "schedule_config = {\"schedule_name\": \"OFDMA slots\",\n",
    "                   \"qbv_window_size\": 1500\n",
    "                   }\n",
    "\n",
    "\n",
    "\n",
    "# Network properties\n",
    "# Obtained from the sheet\n",
    "wifi_slot_time = 9 # microseconds\n",
    "DIFS = 34 # microseconds\n",
    "\n",
    "\n",
    "\n",
    "# Plot information\n",
    "percentile_to_plot = 99\n",
    "num_iterations_contention = [5]*len(lambda_range)\n",
    "mode_contention = \"Mode 4\" \n",
    "advance_time = 10 # microseconds\n",
    "debug_mode = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(delivery_latency[\"contention\"])\n",
    "dummy_window_length = 800\n",
    "print(\"min\", bisect.bisect_right(delivery_latency[\"contention\"], dummy_window_length-34-135))\n",
    "print(\"max\", bisect.bisect_right(delivery_latency[\"contention\"], dummy_window_length-34))\n",
    "print(\"average\", bisect.bisect_right(delivery_latency[\"contention\"], dummy_window_length-34-67.5))\n",
    "\n",
    "\n",
    "\n",
    "lambda_value = 700*10**-6\n",
    "for delivery_latency_index in range(len(delivery_latency[\"contention\"])):\n",
    "    delivery_latency_value = delivery_latency[\"contention\"][delivery_latency_index]\n",
    "    slot_length_temp = DIFS + 0 + delivery_latency_value\n",
    "    if num_UEs*slot_length_temp*lambda_value < delivery_latency_index:\n",
    "        print(num_UEs*slot_length_temp*lambda_value)\n",
    "        print(delivery_latency_index)\n",
    "        print(delivery_latency_value)\n",
    "        print(slot_length_temp)\n",
    "        break\n",
    "    elif delivery_latency_index == len(delivery_latency[\"contention\"])-1:\n",
    "        print(\"Not enough\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_lengths_this_slot = {\"UE2\": 13, \"UE0\": 5, \"UE6\": 10, \"UE1\": 42}\n",
    "\n",
    "# Sort the dictionary by values in descending order and extract the keys\n",
    "sorted_ue_names = sorted(queue_lengths_this_slot, key=queue_lengths_this_slot.get, reverse=True)\n",
    "\n",
    "print(sorted_ue_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_iterations_contention)\n",
    "assert len(num_iterations_contention) == len(lambda_range), \"Lengths not equal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory_simulation = \"../results/simulation_4/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(lambda_range) == len(num_iterations_contention), \"Lengths not equal\"\n",
    "print(lambda_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_contention, cycle_time = create_schedule(UE_names, start_offset, end_time,\\\n",
    "                                      schedule_config)\n",
    "print(schedule_contention)\n",
    "\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Plotting the schedule\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "# Define Y-axis labels and their corresponding positions\n",
    "ue_positions = {ue: i for i, ue in enumerate(UE_names)}\n",
    "height = 1  # Height of the rectangles\n",
    "\n",
    "# Plot rectangles for each slot\n",
    "for slot in schedule_contention.schedule.values():\n",
    "    for ue in slot.UEs:\n",
    "        if slot.mode == \"contention\":\n",
    "            rect = Rectangle((slot.start_time, ue_positions[ue] - height / 2), slot.end_time - slot.start_time, height, color='red', alpha=0.8)\n",
    "        elif slot.mode == \"OFDMA\":\n",
    "            rect = Rectangle((slot.start_time, ue_positions[ue] - height / 2), slot.end_time - slot.start_time, height, facecolor='green', alpha=0.8, edgecolor='black', linewidth = 0.5)\n",
    "        ax.add_patch(rect)\n",
    "        # ax.text((slot.start_time + slot.end_time) / 2, ue_positions[ue], ue, horizontalalignment='center', verticalalignment='center')\n",
    "        \n",
    "        ax.plot([slot.start_time, slot.start_time], [ue_positions[ue] - height / 2, ue_positions[ue] + height / 2], color='black', linewidth=1.6)\n",
    "        ax.plot([slot.end_time, slot.end_time], [ue_positions[ue] - height / 2, ue_positions[ue] + height / 2], color='black', linewidth=1.6)\n",
    "\n",
    "\n",
    "# Set Y-axis with UE names\n",
    "ax.set_yticks(list(ue_positions.values()))\n",
    "ax.set_yticklabels(UE_names)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Time (microseconds)')\n",
    "ax.set_title('UE Activity Schedule')\n",
    "\n",
    "# Set limits for the axes\n",
    "ax.set_xlim(start_offset, cycle_time)\n",
    "ax.set_ylim(-1, len(UE_names))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create UEs and serve the packets, not integrated with result extraction\n",
    "\n",
    "results_per_lambda_contention = {}\n",
    "\n",
    "count = 0\n",
    "\n",
    "execution_start_time = time.time()\n",
    "\n",
    "for lambda_value in lambda_range:\n",
    "    \n",
    "    print(\"\\n###### Lambda value: \" + str(lambda_value), \", Count: \" + str(count), \"######\")\n",
    "    \n",
    "    \n",
    "    results_per_lambda_per_iteration_contention = {}\n",
    "    for num_arrival_iteration in range(num_iterations_arrival):\n",
    "        print(\"\\nArrival iteration: \" + str(num_arrival_iteration))\n",
    "        # Create UEs and packets\n",
    "        \n",
    "        UEs_contention = {}\n",
    "        \n",
    "        time_generate_ues_start = time.time()\n",
    "        for i in range(num_UEs): \n",
    "            # TODO: Move the UE creation parameters to the cell above?\n",
    "            UE_temp = UE(i, {1: 0, 2: 1}, UE_arrival[i], UE_serve_mode[i],  num_packets_per_ue, \\\n",
    "                         CWmin=CWmin, CWmax=CWmax)\n",
    "            UE_temp.set_poisson_lambda(lambda_value)\n",
    "            UE_temp.initialize_transmission_record(schedule_contention)\n",
    "            UE_temp.generate_packets(schedule_contention, packet_sizes, priorities) # TODO: Change this\n",
    "            UEs_contention[UE_names[i]] = UE_temp\n",
    "        time_generate_ues_finish = time.time()\n",
    "\n",
    "        \n",
    "\n",
    "        # TODO: Check that the delivery times are always in ascending order\n",
    "        # TODO: check that the arrival times are always in ascending order\n",
    "\n",
    "        # TODO: Make this more general i.e handle packet statuses directly instead of opearting under the \n",
    "        # restrictions of this simulation\n",
    "        print(\"Num packets: \" + str(UEs_contention[\"UE0\"].n_packets))\n",
    "\n",
    "\n",
    "        # Serve the packets with contention\n",
    "        results_iteration = {}\n",
    "        \n",
    "\n",
    "        for i in range(num_iterations_contention[count]):\n",
    "            print(\"Contention iteration: \" + str(i))\n",
    "            time_deep_copy_ues_start = time.time()\n",
    "            UEs_contention_temp = copy.deepcopy(UEs_contention)\n",
    "            time_deep_copy_ues_finish = time.time()\n",
    "\n",
    "            print(\"Generate test network\")\n",
    "            test_network = Network(wifi_slot_time, DIFS, UEs_contention_temp, debug_mode)\n",
    "\n",
    "            time_serve_packets_start = time.time()  \n",
    "            # %lprun -f Network.serve_packets test_network.serve_packets(schedule_contention,\\\n",
    "            #                                     mode_contention, \\\n",
    "            #                                     payload_size = payload_size, \\\n",
    "            #                                     delivery_latency = delivery_latency, \\\n",
    "            #                                     PER = PER, advance_time = advance_time, \\\n",
    "            #                                     aggregation_limit = aggregation_limit)\n",
    "            test_network.serve_packets(schedule_contention,\\\n",
    "                                                mode_contention, \\\n",
    "                                                payload_size = payload_size, \\\n",
    "                                                delivery_latency = delivery_latency, \\\n",
    "                                                PER = PER, advance_time = advance_time, \\\n",
    "                                                aggregation_limit = aggregation_limit)\n",
    "            time_serve_packets_finish = time.time()\n",
    "\n",
    "            # TODO: remove this\n",
    "            # print(\"Base schedule:\", schedule_contention)\n",
    "            \n",
    "\n",
    "            print(\"Save UEs_contetion_temp\")\n",
    "            results_iteration[i] = UEs_contention_temp \n",
    "        # for key in results_iteration:\n",
    "        #     print(\"results_iteration \" + str(key), results_iteration[key])\n",
    "\n",
    "        # TODO: Scale to multiple UEs, currently you're extracting the results only for one UE,\n",
    "        # but you should be extracting the results for all UEs\n",
    "        \n",
    "        print(\"Save results_iteration\")\n",
    "        results_per_lambda_per_iteration_contention[num_arrival_iteration] = results_iteration\n",
    "    \n",
    "    print(\"Save results_per_lambda_per_iteration_contention\")\n",
    "    %time results_per_lambda_contention[lambda_value] = results_per_lambda_per_iteration_contention\n",
    "    count = count + 1\n",
    "    \n",
    "\n",
    "execution_finish_time = time.time()\n",
    "execution_duration = execution_finish_time - execution_start_time\n",
    "\n",
    "\n",
    "print(\"Execution duration: \" + str(execution_duration))\n",
    "print(\"Generate ues duration: \" + str(time_generate_ues_finish - time_generate_ues_start))\n",
    "print(\"Serve packets duration: \" + str(time_serve_packets_finish - time_serve_packets_start))\n",
    "print(\"Deep copy ues duration: \" + str(time_deep_copy_ues_finish - time_deep_copy_ues_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find slots that UEs are allowed to transmit in and print UEs\n",
    "UE_to_times = {}\n",
    "for UE_name in UE_names:\n",
    "    UE_to_times[UE_name] = []\n",
    "\n",
    "print(UE_to_times)\n",
    "\n",
    "for slot in schedule_contention.schedule:\n",
    "    for UE_name in schedule_contention.schedule[slot].UEs:\n",
    "        UE_to_times[UE_name].append((schedule_contention.schedule[slot].start_time, schedule_contention.schedule[slot].end_time))\n",
    "\n",
    "print(UE_to_times)\n",
    "# del UE_to_times[\"UE0\"][-1]\n",
    "for ue in UEs_contention_temp:\n",
    "    print(\"UE: \" + str(ue))\n",
    "    print(UEs_contention_temp[ue])\n",
    "    # for packet in UEs_contention_temp[ue].packets:\n",
    "    #     if packet.delivery_time is not None:\n",
    "    #         assert packet.arrival_time < packet.delivery_time\n",
    "    #         correct_slot_delivery = False\n",
    "    #         for slot_times in UE_to_times[ue]:\n",
    "    #             if packet.delivery_time >= slot_times[0] and packet.delivery_time <= slot_times[1]:\n",
    "    #                 correct_slot_delivery = True\n",
    "    #                 break\n",
    "            # assert correct_slot_delivery, \"Delivery time not in correct slot : \" + str(packet.sequence_number) + \" \" + str(packet.delivery_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the results\n",
    "\n",
    "\n",
    "results_allUEs_per_lambda_contention = {}\n",
    "for lambda_value in results_per_lambda_contention:\n",
    "    print(\"\\n\\nlambda value: \", lambda_value)\n",
    "\n",
    "    mean_latencies_across_arrivals = []\n",
    "    percentile_latencies_across_arrivals = []\n",
    "    n_packets_not_served_across_arrivals = []\n",
    "    contention_wins_across_arrivals = []\n",
    "    bus_occupancy_across_arrivals = []\n",
    "    queue_slope_across_arrivals = []\n",
    "\n",
    "    for num_iteration_arrival in [0]:\n",
    "        mean_latencies = []\n",
    "        percentile_latencies = []\n",
    "        n_packets_not_served_array = []\n",
    "        contention_wins = []\n",
    "        bus_occupancy = []\n",
    "        queue_slope = []\n",
    "        print(\"arrival iteration \" + str(num_iteration_arrival))\n",
    "        for iteration in results_per_lambda_contention[lambda_value][num_iteration_arrival]:\n",
    "            latencies = []\n",
    "            bus_occupancy_across_ues = []\n",
    "            contention_wins_across_ues = []\n",
    "            queue_slope_across_ues = []\n",
    "            n_packets_not_served = 0\n",
    "            # print(\"iteration\", iteration)\n",
    "            for ue in results_per_lambda_contention[lambda_value][num_iteration_arrival][iteration]:\n",
    "                print(\"UE: \", ue)\n",
    "                UE_temp = results_per_lambda_contention[lambda_value][num_iteration_arrival][iteration][ue]\n",
    "                print(UE_temp)\n",
    "                latencies_UE = UE_temp.obtain_packet_latency()\n",
    "                print(latencies_UE)\n",
    "                latencies_UE = [latency for latency in latencies_UE if latency is not None]\n",
    "                n_packets_not_served += UE_temp.n_packets - len(latencies_UE)\n",
    "                latencies.extend(latencies_UE)\n",
    "                \n",
    "                contention_wins_across_ues.append(UE_temp.transmission_record[0][\"num_wins\"])\n",
    "                bus_occupancy_across_ues.append(np.mean(UE_temp.transmission_record[0][\"num_transmissions\"]))\n",
    "                # print(bus_occupancy_across_ues)\n",
    "                \n",
    "                queue_lengths = []\n",
    "                queue_times = []\n",
    "                for slot in UE_temp.transmission_record:\n",
    "                    queue_lengths.extend(UE_temp.transmission_record[slot][\"queue_information\"][\"queue_lengths\"])\n",
    "                    queue_times.extend(UE_temp.transmission_record[slot][\"queue_information\"][\"queue_times\"])\n",
    "\n",
    "                # queue_lengths = np.array(UE_temp.transmission_record[0][\"queue_information\"][\"queue_lengths\"])\n",
    "                # queue_times = np.array(UE_temp.transmission_record[0][\"queue_information\"][\"queue_times\"])\n",
    "                # TODO: add a scaling factor\n",
    "                # queue_slopes = (queue_lengths[1:] - queue_lengths[:-1])/(queue_times[1:] - queue_times[:-1])\n",
    "                # queue_slope_across_ues.append(np.mean(queue_slopes))\n",
    "                slope, intercept = np.polyfit(queue_times, queue_lengths, 1)\n",
    "                queue_slope_across_ues.append(slope)\n",
    "\n",
    "\n",
    "            print(\"iteration\", iteration)    \n",
    "            mean_latencies.append(np.mean(latencies))\n",
    "            percentile_latencies.append(compute_percentile(latencies, percentile_to_plot))\n",
    "            n_packets_not_served_array.append(n_packets_not_served)\n",
    "            contention_wins.append(np.mean(contention_wins_across_ues))\n",
    "            bus_occupancy.append(np.mean(bus_occupancy_across_ues))\n",
    "            queue_slope.append(np.mean(queue_slope_across_ues))\n",
    "\n",
    "        print(\"Len(mean_latencies)\", len(mean_latencies))\n",
    "        mean_latencies_across_arrivals.append(np.mean(mean_latencies))\n",
    "        percentile_latencies_across_arrivals.append(np.mean(percentile_latencies))\n",
    "        n_packets_not_served_across_arrivals.append(np.mean(n_packets_not_served_array))\n",
    "        contention_wins_across_arrivals.append(np.mean(contention_wins))\n",
    "        bus_occupancy_across_arrivals.append(np.mean(bus_occupancy))\n",
    "        queue_slope_across_arrivals.append(np.mean(queue_slope))\n",
    "\n",
    "    result_temp = {}        \n",
    "    result_temp[\"mean_latency\"] = np.mean(mean_latencies_across_arrivals)\n",
    "    print(\"mean_latencies_across_arrivals\", mean_latencies_across_arrivals)\n",
    "    \n",
    "    result_temp[\"mean_latency_std\"] = np.std(mean_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency\"] = np.mean(percentile_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency_std\"] = np.std(percentile_latencies_across_arrivals)\n",
    "    result_temp[\"n_packets_not_served\"] = np.mean(n_packets_not_served_across_arrivals)\n",
    "    result_temp[\"n_packets_not_served_std\"] = np.std(n_packets_not_served_across_arrivals)\n",
    "    result_temp[\"contention_wins\"] = np.mean(contention_wins_across_arrivals)\n",
    "    result_temp[\"bus_occupancy\"] = np.mean(bus_occupancy_across_arrivals)\n",
    "    result_temp[\"queue_slope\"] = np.mean(queue_slope_across_arrivals)\n",
    "    results_allUEs_per_lambda_contention[lambda_value] = result_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UE_name = \"UE3\"\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "UE_queue_plot = results_per_lambda_contention[lambda_range[0]][0][0][\"UE0\"]\n",
    "for slot in UE_queue_plot.transmission_record:\n",
    "    print(\"Slot: \" + str(slot))\n",
    "    y += UE_queue_plot.transmission_record[slot][\"queue_information\"][\"queue_lengths\"]\n",
    "    print(UE_queue_plot.transmission_record[slot][\"queue_information\"][\"queue_lengths\"])\n",
    "    x += UE_queue_plot.transmission_record[slot][\"queue_information\"][\"queue_times\"]\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "plt.title(\"Queue length vs time\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Queue length\")\n",
    "plt.plot(x, y, label = \"queue information\")\n",
    "plt.plot(x, slope*np.array(x) + intercept, label = \"best fit line\")\n",
    "print(slope)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a results directory folder using results_directory_simulation and the current time\n",
    "experiment_folder_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "results_directory_experiment = os.path.join(results_directory_simulation, experiment_folder_name)\n",
    "os.makedirs(results_directory_experiment, exist_ok=True)\n",
    "# Plots: CDF of latencies, percentile latency vs lambda, mean latency vs lambda,\n",
    "# number of packets not served vs lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the results\n",
    "\n",
    "\n",
    "results_allUEs_per_lambda_contention = {}\n",
    "for lambda_value in results_per_lambda_contention:\n",
    "    print(\"\\n\\nlambda value: \", lambda_value)\n",
    "\n",
    "    mean_latencies_across_arrivals = []\n",
    "    percentile_latencies_across_arrivals = []\n",
    "    n_packets_not_served_across_arrivals = []\n",
    "    contention_wins_across_arrivals = []\n",
    "    bus_occupancy_across_arrivals = []\n",
    "    queue_slope_across_arrivals = []\n",
    "\n",
    "    for num_iteration_arrival in results_per_lambda_contention[lambda_value]:\n",
    "        mean_latencies = []\n",
    "        percentile_latencies = []\n",
    "        n_packets_not_served_array = []\n",
    "        contention_wins = []\n",
    "        bus_occupancy = []\n",
    "        queue_slope = []\n",
    "        print(\"arrival iteration \" + str(num_iteration_arrival))\n",
    "        for iteration in results_per_lambda_contention[lambda_value][num_iteration_arrival]:\n",
    "            latencies = []\n",
    "            bus_occupancy_across_ues = []\n",
    "            contention_wins_across_ues = []\n",
    "            queue_slope_across_ues = []\n",
    "            n_packets_not_served = 0\n",
    "            # print(\"iteration\", iteration)\n",
    "            for ue in results_per_lambda_contention[lambda_value][num_iteration_arrival][iteration]:\n",
    "                # print(\"UE: \", ue)\n",
    "                UE_temp = results_per_lambda_contention[lambda_value][num_iteration_arrival][iteration][ue]\n",
    "                latencies_UE = UE_temp.obtain_packet_latency()\n",
    "                latencies_UE = [latency for latency in latencies_UE if latency is not None]\n",
    "                n_packets_not_served += UE_temp.n_packets - len(latencies_UE)\n",
    "                latencies.extend(latencies_UE)\n",
    "                \n",
    "                contention_wins_across_ues.append(UE_temp.transmission_record[0][\"num_wins\"])\n",
    "                bus_occupancy_across_ues.append(np.mean(UE_temp.transmission_record[0][\"num_transmissions\"]))\n",
    "                # print(bus_occupancy_across_ues)\n",
    "                \n",
    "                queue_lengths = []\n",
    "                queue_times = []\n",
    "                for slot in UE_temp.transmission_record:\n",
    "                    queue_lengths.extend(UE_temp.transmission_record[slot][\"queue_information\"][\"queue_lengths\"])\n",
    "                    queue_times.extend(UE_temp.transmission_record[slot][\"queue_information\"][\"queue_times\"])\n",
    "\n",
    "                # queue_lengths = np.array(UE_temp.transmission_record[0][\"queue_information\"][\"queue_lengths\"])\n",
    "                # queue_times = np.array(UE_temp.transmission_record[0][\"queue_information\"][\"queue_times\"])\n",
    "                # TODO: add a scaling factor\n",
    "                # queue_slopes = (queue_lengths[1:] - queue_lengths[:-1])/(queue_times[1:] - queue_times[:-1])\n",
    "                # queue_slope_across_ues.append(np.mean(queue_slopes))\n",
    "                slope, intercept = np.polyfit(queue_times, queue_lengths, 1)\n",
    "                queue_slope_across_ues.append(slope)\n",
    "\n",
    "\n",
    "            print(\"iteration\", iteration)    \n",
    "            mean_latencies.append(np.mean(latencies))\n",
    "            percentile_latencies.append(compute_percentile(latencies, percentile_to_plot))\n",
    "            n_packets_not_served_array.append(n_packets_not_served)\n",
    "            contention_wins.append(np.mean(contention_wins_across_ues))\n",
    "            bus_occupancy.append(np.mean(bus_occupancy_across_ues))\n",
    "            queue_slope.append(np.mean(queue_slope_across_ues))\n",
    "\n",
    "        print(\"Len(mean_latencies)\", len(mean_latencies))\n",
    "        mean_latencies_across_arrivals.append(np.mean(mean_latencies))\n",
    "        percentile_latencies_across_arrivals.append(np.mean(percentile_latencies))\n",
    "        n_packets_not_served_across_arrivals.append(np.mean(n_packets_not_served_array))\n",
    "        contention_wins_across_arrivals.append(np.mean(contention_wins))\n",
    "        bus_occupancy_across_arrivals.append(np.mean(bus_occupancy))\n",
    "        queue_slope_across_arrivals.append(np.mean(queue_slope))\n",
    "\n",
    "    result_temp = {}        \n",
    "    result_temp[\"mean_latency\"] = np.mean(mean_latencies_across_arrivals)\n",
    "    print(\"mean_latencies_across_arrivals\", mean_latencies_across_arrivals)\n",
    "    \n",
    "    result_temp[\"mean_latency_std\"] = np.std(mean_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency\"] = np.mean(percentile_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency_std\"] = np.std(percentile_latencies_across_arrivals)\n",
    "    result_temp[\"n_packets_not_served\"] = np.mean(n_packets_not_served_across_arrivals)\n",
    "    result_temp[\"n_packets_not_served_std\"] = np.std(n_packets_not_served_across_arrivals)\n",
    "    result_temp[\"contention_wins\"] = np.mean(contention_wins_across_arrivals)\n",
    "    result_temp[\"bus_occupancy\"] = np.mean(bus_occupancy_across_arrivals)\n",
    "    result_temp[\"queue_slope\"] = np.mean(queue_slope_across_arrivals)\n",
    "    results_allUEs_per_lambda_contention[lambda_value] = result_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters and the results of the experiment to a file\n",
    "experiment_parameters = {\n",
    "        \"config_file\": config_file,\n",
    "        \"setting_reserved\": parameters[setting_reserved],\n",
    "        \"setting_contention\": parameters[setting_contention],\n",
    "        \"aggregation_limit\": aggregation_limit,\n",
    "        \"schedule_config\": schedule_config,\n",
    "        \"num_UEs\": num_UEs,\n",
    "        \"num_packets_per_ue\": num_packets_per_ue,\n",
    "        \"packet_sizes\": packet_sizes,\n",
    "        \"priorities\": priorities,\n",
    "        \"UE_arrival\": UE_arrival,\n",
    "        \"UE_serve_mode\": UE_serve_mode,\n",
    "        \"start_offset\": start_offset, # microseconds\n",
    "        \"end_time\": end_time,\n",
    "        \"percentile_to_plot\": percentile_to_plot,\n",
    "        \"wifi_slot_time\": wifi_slot_time,\n",
    "        \"DIFS\": DIFS,\n",
    "        \"num_iterations_contention\": num_iterations_contention,\n",
    "        \"num_iterations_arrival\": num_iterations_arrival,\n",
    "        \"contention_mode\": mode_contention,\n",
    "        \"advance_time\": advance_time,\n",
    "        \"CWmin\": CWmin,\n",
    "        \"CWmax\": CWmax,\n",
    "        \"lambda_range\": lambda_range,\n",
    "        \"execution_duration\": execution_duration,\n",
    "    }\n",
    "# Write experiment_parameters_json to a json file with filename experiment_parameters.json\n",
    "\n",
    "experiment_parameters_json = json.dumps(experiment_parameters, indent=4, cls=NumpyEncoder)\n",
    "experiment_parameters_json_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                   \"experiment_parameters.json\")\n",
    "with open(experiment_parameters_json_filename, \"w\") as file:\n",
    "    file.write(experiment_parameters_json)\n",
    "\n",
    "latencies = UEs_contention_temp[\"UE0\"].obtain_packet_latency()\n",
    "experiment_parameters_pickle = {\n",
    "        \"schedule_contention\": schedule_contention,\n",
    "        \"results_allUEs_per_lambda_contention\": results_allUEs_per_lambda_contention,\n",
    "        \"experiment_parameters\": experiment_parameters\n",
    "    }\n",
    "\n",
    "experiment_parameters_pickle_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                    \"experiment_parameters.pkl\")\n",
    "\n",
    "with open(experiment_parameters_pickle_filename, \"wb\") as file:\n",
    "    pickle.dump(experiment_parameters_pickle, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "lambda_range = lambda_original\n",
    "\n",
    "# lambda_range = lambda_range[:8]\n",
    "\n",
    "scale = \"linear\"\n",
    "percentile_filename = \"percentile_latency_allUEs_all_\" + scale + \".png\"\n",
    "percentile_slope_filename = \"percentile_slope_allUEs_all_\" + scale + \".png\"\n",
    "mean_filename = \"mean_latency_allUEs_all_\" + scale + \".png\"\n",
    "mean_slope_filename = \"mean_slope_allUEs_all_\" + scale + \".png\"\n",
    "n_packets_not_served_filename = \"n_packets_not_served_allUEs_all_\" + scale + \".png\"\n",
    "bus_occupancy_filename = \"bus_occupancy_10UEs_all_extended_\" + scale + \".png\"\n",
    "n_wins_filename = \"n_wins_10UEs_all_extended_\" + scale + \".png\"\n",
    "scaling_factor = 1e6\n",
    "\n",
    "# Plot the percentile curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# percentiles = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     percentiles.append(results_allUEs_per_lambda_reserved[lambda_value][\"percentile_latency\"])\n",
    "# plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time), \\\n",
    "#          percentiles, \".-\", label = \"reserved\")\n",
    "\n",
    "percentiles_contention = []\n",
    "percentiles_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    percentiles_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"percentile_latency\"])\n",
    "    percentiles_contention_std.append(\\\n",
    "        results_allUEs_per_lambda_contention[lambda_value][\"percentile_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*scaling_factor, \\\n",
    "        percentiles_contention, percentiles_contention_std, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(str(percentile_to_plot) + \"percentile latency (us)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 {percentile_to_plot} percentile latency vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.text(0, percentiles_contention[0], str(np.round(percentiles_contention[0],2)), \\\n",
    "         fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "plt.axhline(y=5000, color='r', linestyle='--')\n",
    "plt.ylim(0,100000)\n",
    "# plt.xlim(0, 5000)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(results_directory_experiment, percentile_filename))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "slope = np.diff(percentiles_contention)/(np.diff(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time))\n",
    "plt.title(\"Percentile latency slope\")\n",
    "plt.xlabel(\"lambda*schedule_duration (us)\")\n",
    "plt.ylabel(str(percentile_to_plot) + \"percentile latency slope (us)\")\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "        plt.ylim(10**-2, 10**2)\n",
    "plt.plot(np.array(lambda_range[1:])*(schedule_contention.end_time - schedule_contention.start_time), slope, \".-\")\n",
    "plt.savefig(os.path.join(results_directory_experiment, percentile_slope_filename))\n",
    "\n",
    "print(slope)\n",
    "# Plot the mean latency curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# mean_latencies = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     mean_latencies.append(results_allUEs_per_lambda_reserved[lambda_value][\"mean_latency\"])\n",
    "# plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time),\\\n",
    "#          mean_latencies, \".-\", label = \"reserved\")\n",
    "\n",
    "\n",
    "\n",
    "mean_latencies_contention = []\n",
    "mean_latencies_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    mean_latencies_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"mean_latency\"])\n",
    "    mean_latencies_contention_std.append(\\\n",
    "        results_allUEs_per_lambda_contention[lambda_value][\"mean_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*scaling_factor,\\\n",
    "        mean_latencies_contention, mean_latencies_contention_std, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "\n",
    "\n",
    "plt.text(0, mean_latencies_contention[0], str(np.round(mean_latencies_contention[0],2)), \\\n",
    "         fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "plt.axhline(y=5000, color='r', linestyle='--')\n",
    "plt.ylim(0,15000) \n",
    "# plt.xlim(0, 5000)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Mean latency (us)\")\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 mean latency vs lambda, \\n PER = {PER}, \\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         )\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(results_directory_experiment, mean_filename))\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "slope = np.diff(mean_latencies_contention)/(np.diff(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time))\n",
    "plt.title(\"Mean latency slope\")\n",
    "plt.xlabel(\"lambda*schedule_duration (us)\")\n",
    "plt.ylabel(\"Mean percentile latency slope (us)\")\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "plt.plot(np.array(lambda_range[1:])*(schedule_contention.end_time - schedule_contention.start_time), slope, \".-\")\n",
    "plt.savefig(os.path.join(results_directory_experiment, mean_slope_filename))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# mean_latencies = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     mean_latencies.append(results_allUEs_per_lambda_reserved[lambda_value][\"mean_latency\"])\n",
    "# plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time),\\\n",
    "#          mean_latencies, \".-\", label = \"reserved\")\n",
    "\n",
    "# scale = \"linear\"\n",
    "\n",
    "\n",
    "unserved_packets_contention = []\n",
    "unserved_packets_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    unserved_packets_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"n_packets_not_served\"])\n",
    "    unserved_packets_contention_std.append(\\\n",
    "        results_allUEs_per_lambda_contention[lambda_value][\"n_packets_not_served_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*scaling_factor,\\\n",
    "        np.array(unserved_packets_contention) + 1, np.array(unserved_packets_contention_std) + 0.001, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "\n",
    "\n",
    "# plt.text(0, unserved_packets_contention[0], str(np.round(unserved_packets_contention[0],2)), \\\n",
    "        #  fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Unserved packets\")\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 unserved vs lambda, \\n PER = {PER}, \\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(results_directory_experiment, n_packets_not_served_filename))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bus_occupancy_contention = []\n",
    "for lambda_value in lambda_range:\n",
    "    bus_occupancy_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"bus_occupancy\"])\n",
    "plt.plot(np.array(lambda_range)*scaling_factor, \\\n",
    "        bus_occupancy_contention, '.-', label = \"contention\")\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Bus occupancy\")\n",
    "plt.legend()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 Bus occupancy vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, bus_occupancy_filename))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "wins_contention = []\n",
    "for lambda_value in lambda_range:\n",
    "    wins_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"contention_wins\"])\n",
    "plt.plot(np.array(lambda_range)*scaling_factor, \\\n",
    "        wins_contention, '.-', label = \"contention\")\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Contention wins\")\n",
    "plt.legend()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 num_wins vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, n_wins_filename))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "queue_slope = []\n",
    "for lambda_value in lambda_range:\n",
    "    queue_slope.append(results_allUEs_per_lambda_contention[lambda_value][\"queue_slope\"])\n",
    "plt.plot(np.array(lambda_range)*scaling_factor, \\\n",
    "        queue_slope, '.-', label = \"contention\")\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"queue slope\")\n",
    "plt.legend()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 queue slope vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, n_wins_filename))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bus_occupancy_contention)\n",
    "print(mean_latencies_contention)\n",
    "print(percentiles_contention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating result extraction into the main body of the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a results directory folder using results_directory_simulation and the current time\n",
    "# experiment_folder_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "# results_directory_experiment = os.path.join(results_directory_simulation, experiment_folder_name)\n",
    "# UEs_directory = os.path.join(results_directory_experiment, \"UEs\")\n",
    "# os.makedirs(results_directory_experiment, exist_ok=True)\n",
    "# os.makedirs(UEs_directory, exist_ok=True)\n",
    "# # Plots: CDF of latencies, percentile latency vs lambda, mean latency vs lambda,\n",
    "# # number of packets not served vs lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a schedule, UEs and serve the packets, not integrated with result extraction\n",
    "\n",
    "# slots_temp = {}\n",
    "# slots_temp[0] = Slot(0, start_offset, end_time, \"contention\", UE_names)\n",
    "# schedule_contention = Schedule(start_offset, end_time, 1, slots_temp)\n",
    "\n",
    "\n",
    "# # print(schedule_reserved)\n",
    "# print(schedule_contention)\n",
    "\n",
    "# results_per_lambda_contention = {}\n",
    "\n",
    "# count = 0\n",
    "\n",
    "# execution_start_time = time.time()\n",
    "\n",
    "\n",
    "# results_allUEs_per_lambda_contention = {}\n",
    "\n",
    "# for lambda_value in lambda_range:\n",
    "    \n",
    "#     print(\"\\n###### Lambda value: \" + str(lambda_value), \", Count: \" + str(count), \"######\")\n",
    "    \n",
    "#     mean_latencies_across_arrivals = []\n",
    "#     percentile_latencies_across_arrivals = []\n",
    "#     n_packets_not_served_across_arrivals = []\n",
    "#     contention_wins_across_arrivals = []\n",
    "#     bus_occupancy_across_arrivals = []\n",
    "    \n",
    "#     results_per_lambda_per_iteration_contention = {}\n",
    "#     for num_arrival_iteration in range(num_iterations_arrival):\n",
    "#         print(\"\\nArrival iteration: \" + str(num_arrival_iteration))\n",
    "#         # Create UEs and packets\n",
    "        \n",
    "#         UEs_contention = {}\n",
    "        \n",
    "        \n",
    "#         time_generate_ues_start = time.time()\n",
    "#         for i in range(num_UEs): \n",
    "#             # TODO: Move the UE creation parameters to the cell above?\n",
    "#             UE_temp = UE(i, {1: 0, 2: 1}, UE_arrival[i], UE_serve_mode[i],  num_packets_per_ue, \\\n",
    "#                          CWmin=CWmin, CWmax=CWmax)\n",
    "#             UE_temp.set_poisson_lambda(lambda_value)\n",
    "#             UE_temp.initialize_transmission_record(schedule_contention)\n",
    "#             UE_temp.generate_packets(schedule_contention, packet_sizes, priorities) # TODO: Change this\n",
    "#             UEs_contention[UE_names[i]] = UE_temp\n",
    "#         time_generate_ues_finish = time.time()\n",
    "\n",
    "#         # TODO: Check that the delivery times are always in ascending order\n",
    "#         # TODO: check that the arrival times are always in ascending order\n",
    "\n",
    "#         # TODO: Make this more general i.e handle packet statuses directly instead of opearting under the \n",
    "#         # restrictions of this simulation\n",
    "#         print(\"Num packets: \" + str(UEs_contention[\"UE0\"].n_packets))\n",
    "\n",
    "\n",
    "#         # Serve the packets with contention\n",
    "#         results_iteration = {}\n",
    "#         mean_latencies = []\n",
    "#         percentile_latencies = []\n",
    "#         n_packets_not_served_array = []\n",
    "#         contention_wins = []\n",
    "#         bus_occupancy = []\n",
    "\n",
    "#         for i in range(num_iterations_contention[count]):\n",
    "#             print(\"Contention iteration: \" + str(i))\n",
    "#             time_deep_copy_ues_start = time.time()\n",
    "#             UEs_contention_temp = copy.deepcopy(UEs_contention)\n",
    "#             time_deep_copy_ues_finish = time.time()\n",
    "\n",
    "#             print(\"Generate test network\")\n",
    "#             test_network = Network(wifi_slot_time, DIFS, UEs_contention_temp, debug_mode)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "#             time_serve_packets_start = time.time()  \n",
    "#             # %lprun -f Network.serve_packets test_network.serve_packets(schedule_contention,\\\n",
    "#             #                                     mode_contention, \\\n",
    "#             #                                     payload_size = payload_size, \\\n",
    "#             #                                     delivery_latency = delivery_latency, \\\n",
    "#             #                                     PER = PER, advance_time = advance_time)\n",
    "#             test_network.serve_packets(schedule_contention,\\\n",
    "#                                                 mode_contention, \\\n",
    "#                                                 payload_size = payload_size, \\\n",
    "#                                                 delivery_latency = delivery_latency, \\\n",
    "#                                                 PER = PER, advance_time = advance_time)\n",
    "#             time_serve_packets_finish = time.time()\n",
    "\n",
    "#             latencies = []\n",
    "#             bus_occupancy_across_ues = []\n",
    "#             contention_wins_across_ues = []\n",
    "#             n_packets_not_served = 0\n",
    "\n",
    "\n",
    "#             for ue in UEs_contention_temp:\n",
    "#                 # print(\"UE: \", ue)\n",
    "#                 UE_temp = UEs_contention_temp[ue]\n",
    "#                 latencies_UE = UE_temp.obtain_packet_latency()\n",
    "#                 latencies_UE = [latency for latency in latencies_UE if latency is not None]\n",
    "#                 n_packets_not_served += UE_temp.n_packets - len(latencies_UE)\n",
    "#                 latencies.extend(latencies_UE)\n",
    "#                 contention_wins_across_ues.append(UE_temp.transmission_record[0][\"num_wins\"])\n",
    "#                 bus_occupancy_across_ues.append(np.mean(UE_temp.transmission_record[0][\"num_transmissions\"]))\n",
    "            \n",
    "#             mean_latencies.append(np.mean(latencies))\n",
    "#             percentile_latencies.append(compute_percentile(latencies, percentile_to_plot))\n",
    "#             n_packets_not_served_array.append(n_packets_not_served)\n",
    "#             contention_wins.append(np.mean(contention_wins_across_ues))\n",
    "#             bus_occupancy.append(np.mean(bus_occupancy_across_ues))\n",
    "\n",
    "#             print(\"Save UEs_contetion_temp\")\n",
    "#             # results_iteration[i] = UEs_contention_temp\n",
    "#             UEs_filename = os.path.join(UEs_directory, \"UEs_contention_\" + \\\n",
    "#                                         str(count) + \"_\" + str(num_arrival_iteration) + \"_\" + \\\n",
    "#                                         str(i) + \".pkl\")\n",
    "#             with open(UEs_filename, \"wb\") as file:\n",
    "#                 pickle.dump(UEs_contention_temp, file) \n",
    "        \n",
    "#         mean_latencies_across_arrivals.append(np.mean(mean_latencies))\n",
    "#         percentile_latencies_across_arrivals.append(np.mean(percentile_latencies))\n",
    "#         n_packets_not_served_across_arrivals.append(np.mean(n_packets_not_served_array))\n",
    "#         contention_wins_across_arrivals.append(np.mean(contention_wins))\n",
    "#         bus_occupancy_across_arrivals.append(np.mean(bus_occupancy))\n",
    "        \n",
    "#         # for key in results_iteration:\n",
    "#         #     print(\"results_iteration \" + str(key), results_iteration[key])\n",
    "\n",
    "#         # TODO: Scale to multiple UEs, currently you're extracting the results only for one UE,\n",
    "#         # but you should be extracting the results for all UEs\n",
    "        \n",
    "#         print(\"Save results_iteration\")\n",
    "#         # results_per_lambda_per_iteration_contention[num_arrival_iteration] = results_iteration\n",
    "    \n",
    "#     result_temp = {}        \n",
    "#     result_temp[\"mean_latency\"] = np.mean(mean_latencies_across_arrivals)\n",
    "#     result_temp[\"mean_latency_std\"] = np.std(mean_latencies_across_arrivals)\n",
    "#     result_temp[\"percentile_latency\"] = np.mean(percentile_latencies_across_arrivals)\n",
    "#     result_temp[\"percentile_latency_std\"] = np.std(percentile_latencies_across_arrivals)\n",
    "#     result_temp[\"n_packets_not_served\"] = np.mean(n_packets_not_served_across_arrivals)\n",
    "#     result_temp[\"n_packets_not_served_std\"] = np.std(n_packets_not_served_across_arrivals)\n",
    "#     result_temp[\"contention_wins\"] = np.mean(contention_wins_across_arrivals)\n",
    "#     result_temp[\"bus_occupancy\"] = np.mean(bus_occupancy_across_arrivals)\n",
    "#     results_allUEs_per_lambda_contention[lambda_value] = result_temp\n",
    "    \n",
    "#     print(\"Save results_per_lambda_per_iteration_contention\")\n",
    "#     results_per_lambda_contention[lambda_value] = results_per_lambda_per_iteration_contention\n",
    "#     count = count + 1\n",
    "    \n",
    "\n",
    "# execution_finish_time = time.time()\n",
    "# execution_duration = execution_finish_time - execution_start_time\n",
    "\n",
    "\n",
    "# print(\"Execution duration: \" + str(execution_duration))\n",
    "# print(\"Generate ues duration: \" + str(time_generate_ues_finish - time_generate_ues_start))\n",
    "# print(\"Serve packets duration: \" + str(time_serve_packets_finish - time_serve_packets_start))\n",
    "# print(\"Deep copy ues duration: \" + str(time_deep_copy_ues_finish - time_deep_copy_ues_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a results directory folder using results_directory_simulation and the current time\n",
    "# experiment_folder_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "# results_directory_experiment = os.path.join(results_directory_simulation, experiment_folder_name)\n",
    "# os.makedirs(results_directory_experiment, exist_ok=True)\n",
    "# # Plots: CDF of latencies, percentile latency vs lambda, mean latency vs lambda,\n",
    "# # number of packets not served vs lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the parameters and the results of the experiment to a file\n",
    "\n",
    "# experiment_parameters = {\n",
    "#     \"config_file\": config_file,\n",
    "#     \"setting_reserved\": parameters[setting_reserved],\n",
    "#     \"setting_contention\": parameters[setting_contention],\n",
    "#     \"num_UEs\": num_UEs,\n",
    "#     \"num_packets_per_ue\": num_packets_per_ue,\n",
    "#     \"packet_sizes\": packet_sizes,\n",
    "#     \"priorities\": priorities,\n",
    "#     \"UE_arrival\": UE_arrival,\n",
    "#     \"UE_serve_mode\": UE_serve_mode,\n",
    "#     \"start_offset\": start_offset, # microseconds\n",
    "#     \"end_time\": end_time,\n",
    "#     \"percentile_to_plot\": percentile_to_plot,\n",
    "#     \"wifi_slot_time\": wifi_slot_time,\n",
    "#     \"DIFS\": DIFS,\n",
    "#     \"num_iterations_contention\": num_iterations_contention,\n",
    "#     \"num_iterations_arrival\": num_iterations_arrival,\n",
    "#     \"contention_mode\": mode_contention,\n",
    "#     \"advance_time\": advance_time,\n",
    "#     \"CWmin\": CWmin,\n",
    "#     \"CWmax\": CWmax,\n",
    "#     \"lambda_range\": lambda_range,\n",
    "#     \"execution_duration\": execution_duration\n",
    "# }\n",
    "\n",
    "# # Write experiment_parameters_json to a json file with filename experiment_parameters.json\n",
    "\n",
    "# experiment_parameters_json = json.dumps(experiment_parameters, indent=4, cls=NumpyEncoder)\n",
    "# experiment_parameters_json_filename = os.path.join(results_directory_experiment, \\\n",
    "#                                                    \"experiment_parameters.json\")\n",
    "# with open(experiment_parameters_json_filename, \"w\") as file:\n",
    "#     file.write(experiment_parameters_json)\n",
    "\n",
    "# latencies = UEs_contention_temp[\"UE0\"].obtain_packet_latency()\n",
    "# experiment_parameters_pickle = {\n",
    "#     # \"schedule_contention\": schedule_contention,\n",
    "#     # \"results_per_lambda_contention\": results_per_lambda_contention,\n",
    "#     # \"results_allUEs_per_lambda_reserved\": results_per_lambda_per_iteration_contention,\n",
    "#     \"UEs_contention\": mean_latencies_across_arrivals,\n",
    "#     # \"results_allUEs_per_lambda_contention\": results_allUEs_per_lambda_contention,\n",
    "#     # \"experiment_parameters\": experiment_parameters\n",
    "# }\n",
    "\n",
    "# experiment_parameters_pickle_filename = os.path.join(results_directory_experiment, \\\n",
    "#                                                     \"experiment_parameters.pkl\")\n",
    "\n",
    "# with open(experiment_parameters_pickle_filename, \"wb\") as file:\n",
    "#     pickle.dump(experiment_parameters_pickle, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the results\n",
    "\n",
    "# lambda_range = lambda_original\n",
    "\n",
    "# # lambda_range = lambda_range[:8]\n",
    "\n",
    "# scale = \"linear\"\n",
    "# percentile_filename = \"percentile_latency_allUEs_all_\" + scale + \".png\"\n",
    "# percentile_slope_filename = \"percentile_slope_allUEs_all_\" + scale + \".png\"\n",
    "# mean_filename = \"mean_latency_allUEs_all_\" + scale + \".png\"\n",
    "# mean_slope_filename = \"mean_slope_allUEs_all_\" + scale + \".png\"\n",
    "# n_packets_not_served_filename = \"n_packets_not_served_allUEs_all_\" + scale + \".png\"\n",
    "# bus_occupancy_filename = \"bus_occupancy_10UEs_all_extended_\" + scale + \".png\"\n",
    "# n_wins_filename = \"n_wins_10UEs_all_extended_\" + scale + \".png\"\n",
    "# scaling_factor = 1e6\n",
    "\n",
    "# # Plot the percentile curve\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# # percentiles = []\n",
    "# # for lambda_value in lambda_range:\n",
    "# #     percentiles.append(results_allUEs_per_lambda_reserved[lambda_value][\"percentile_latency\"])\n",
    "# # plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time), \\\n",
    "# #          percentiles, \".-\", label = \"reserved\")\n",
    "\n",
    "# percentiles_contention = []\n",
    "# percentiles_contention_std = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     percentiles_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"percentile_latency\"])\n",
    "#     percentiles_contention_std.append(\\\n",
    "#         results_allUEs_per_lambda_contention[lambda_value][\"percentile_latency_std\"])\n",
    "# plt.errorbar(np.array(lambda_range)*scaling_factor, \\\n",
    "#         percentiles_contention, percentiles_contention_std, label = \"contention\", fmt='.-', \\\n",
    "#         capsize=3)\n",
    "# # plt.plot(n_packets_generated, percentiles)\n",
    "# plt.xlabel(\"lambda (packets/s)\")\n",
    "# plt.ylabel(str(percentile_to_plot) + \"percentile latency (us)\")\n",
    "# plt.legend()\n",
    "\n",
    "# if scale == \"log\":\n",
    "#         plt.yscale('log')\n",
    "\n",
    "# title = (f\"Simulation 3 {percentile_to_plot} percentile latency vs lambda, \\n PER = {PER},\\n\"\n",
    "#          f\"num_UEs: {num_UEs}, \\n\"\n",
    "#          f\"allowed_payload: {payload_size} B, \\n \"\n",
    "#          f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "#          f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "#         )\n",
    "# plt.title(title)\n",
    "# # Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "# plt.text(0, percentiles_contention[0], str(np.round(percentiles_contention[0],2)), \\\n",
    "#          fontsize=12, verticalalignment='bottom')\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n",
    "# plt.savefig(os.path.join(results_directory_experiment, percentile_filename))\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# slope = np.diff(percentiles_contention)/(np.diff(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time))\n",
    "# plt.title(\"Percentile latency slope\")\n",
    "# plt.xlabel(\"lambda*schedule_duration (us)\")\n",
    "# plt.ylabel(str(percentile_to_plot) + \"percentile latency slope (us)\")\n",
    "# if scale == \"log\":\n",
    "#         plt.yscale('log')\n",
    "#         plt.ylim(10**-2, 10**2)\n",
    "# plt.plot(np.array(lambda_range[1:])*(schedule_contention.end_time - schedule_contention.start_time), slope, \".-\")\n",
    "# plt.savefig(os.path.join(results_directory_experiment, percentile_slope_filename))\n",
    "\n",
    "# print(slope)\n",
    "# # Plot the mean latency curve\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# # mean_latencies = []\n",
    "# # for lambda_value in lambda_range:\n",
    "# #     mean_latencies.append(results_allUEs_per_lambda_reserved[lambda_value][\"mean_latency\"])\n",
    "# # plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time),\\\n",
    "# #          mean_latencies, \".-\", label = \"reserved\")\n",
    "\n",
    "\n",
    "\n",
    "# mean_latencies_contention = []\n",
    "# mean_latencies_contention_std = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     mean_latencies_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"mean_latency\"])\n",
    "#     mean_latencies_contention_std.append(\\\n",
    "#         results_allUEs_per_lambda_contention[lambda_value][\"mean_latency_std\"])\n",
    "# plt.errorbar(np.array(lambda_range)*scaling_factor,\\\n",
    "#         mean_latencies_contention, mean_latencies_contention_std, label = \"contention\", fmt='.-', \\\n",
    "#         capsize=3)\n",
    "\n",
    "\n",
    "# plt.text(0, mean_latencies_contention[0], str(np.round(mean_latencies_contention[0],2)), \\\n",
    "#          fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.xlabel(\"lambda (packets/s)\")\n",
    "# plt.ylabel(\"Mean latency (us)\")\n",
    "\n",
    "# if scale == \"log\":\n",
    "#         plt.yscale('log')\n",
    "\n",
    "# title = (f\"Simulation 3 mean latency vs lambda, \\n PER = {PER}, \\n\"\n",
    "#          f\"num_UEs: {num_UEs}, \\n\"\n",
    "#          f\"allowed_payload: {payload_size} B, \\n \"\n",
    "#          f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "#          f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "#          )\n",
    "# plt.title(title)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.savefig(os.path.join(results_directory_experiment, mean_filename))\n",
    "\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# slope = np.diff(mean_latencies_contention)/(np.diff(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time))\n",
    "# plt.title(\"Mean latency slope\")\n",
    "# plt.xlabel(\"lambda*schedule_duration (us)\")\n",
    "# plt.ylabel(\"Mean percentile latency slope (us)\")\n",
    "# if scale == \"log\":\n",
    "#         plt.yscale('log')\n",
    "# plt.plot(np.array(lambda_range[1:])*(schedule_contention.end_time - schedule_contention.start_time), slope, \".-\")\n",
    "# plt.savefig(os.path.join(results_directory_experiment, mean_slope_filename))\n",
    "\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# # mean_latencies = []\n",
    "# # for lambda_value in lambda_range:\n",
    "# #     mean_latencies.append(results_allUEs_per_lambda_reserved[lambda_value][\"mean_latency\"])\n",
    "# # plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time),\\\n",
    "# #          mean_latencies, \".-\", label = \"reserved\")\n",
    "\n",
    "# # scale = \"linear\"\n",
    "\n",
    "\n",
    "# unserved_packets_contention = []\n",
    "# unserved_packets_contention_std = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     unserved_packets_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"n_packets_not_served\"])\n",
    "#     unserved_packets_contention_std.append(\\\n",
    "#         results_allUEs_per_lambda_contention[lambda_value][\"n_packets_not_served_std\"])\n",
    "# plt.errorbar(np.array(lambda_range)*scaling_factor,\\\n",
    "#         np.array(unserved_packets_contention) + 1, np.array(unserved_packets_contention_std) + 0.001, label = \"contention\", fmt='.-', \\\n",
    "#         capsize=3)\n",
    "\n",
    "\n",
    "# # plt.text(0, unserved_packets_contention[0], str(np.round(unserved_packets_contention[0],2)), \\\n",
    "#         #  fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.xlabel(\"lambda (packets/s)\")\n",
    "# plt.ylabel(\"Unserved packets\")\n",
    "\n",
    "# if scale == \"log\":\n",
    "#         plt.yscale('log')\n",
    "\n",
    "# title = (f\"Simulation 3 unserved vs lambda, \\n PER = {PER}, \\n\"\n",
    "#          f\"num_UEs: {num_UEs}, \\n\"\n",
    "#          f\"allowed_payload: {payload_size} B, \\n \"\n",
    "#          f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "#          f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "#         )\n",
    "# plt.title(title)\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.savefig(os.path.join(results_directory_experiment, n_packets_not_served_filename))\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# bus_occupancy_contention = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     bus_occupancy_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"bus_occupancy\"])\n",
    "# plt.plot(np.array(lambda_range)*scaling_factor, \\\n",
    "#         bus_occupancy_contention, '.-', label = \"contention\")\n",
    "# # plt.plot(n_packets_generated, percentiles)\n",
    "# plt.xlabel(\"lambda (packets/s)\")\n",
    "# plt.ylabel(\"Bus occupancy\")\n",
    "# plt.legend()\n",
    "\n",
    "# if scale == \"log\":\n",
    "#         plt.yscale('log')\n",
    "\n",
    "# title = (f\"Simulation 3 Bus occupancy vs lambda, \\n PER = {PER},\\n\"\n",
    "#          f\"num_UEs: {num_UEs}, \\n\"\n",
    "#          f\"allowed_payload: {payload_size} B, \\n \"\n",
    "#          f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "#          f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "#         )\n",
    "# plt.title(title)\n",
    "# # Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(results_directory_experiment, bus_occupancy_filename))\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# wins_contention = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     wins_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"contention_wins\"])\n",
    "# plt.plot(np.array(lambda_range)*scaling_factor, \\\n",
    "#         wins_contention, '.-', label = \"contention\")\n",
    "# # plt.plot(n_packets_generated, percentiles)\n",
    "# plt.xlabel(\"lambda (packets/s)\")\n",
    "# plt.ylabel(\"Contention wins\")\n",
    "# plt.legend()\n",
    "\n",
    "# if scale == \"log\":\n",
    "#         plt.yscale('log')\n",
    "\n",
    "# title = (f\"Simulation 3 Bus occupancy vs lambda, \\n PER = {PER},\\n\"\n",
    "#          f\"num_UEs: {num_UEs}, \\n\"\n",
    "#          f\"allowed_payload: {payload_size} B, \\n \"\n",
    "#          f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "#          f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "#         )\n",
    "# plt.title(title)\n",
    "# # Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(os.path.join(results_directory_experiment, n_wins_filename))\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scientific_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
