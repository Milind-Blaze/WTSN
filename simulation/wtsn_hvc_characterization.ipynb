{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f569c5d6",
   "metadata": {},
   "source": [
    "# Characterizing WTSN channels\n",
    "\n",
    "This notebooks simulates a basic WTSN system with some UEs, an access point and \n",
    "some base schedules to determine what the packet latencies and throughput are under \n",
    "different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddfc422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulating the WTSN setting\n",
    "\n",
    "Authors: Milind Kumar Vaddiraju, ChatGPT, Copilot\n",
    "\"\"\"\n",
    "\n",
    "# Necessary imports\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from network_classes import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bd3b39",
   "metadata": {},
   "source": [
    "## Dummy simulation\n",
    "\n",
    "Dummy simulation that marks all packets as delivered after a small wait time. Used\n",
    "to test that all classes are functioning as they should."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc530b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a schedule with 2 slots and 2 UEs\n",
    "slot1 = Slot(0, 0, 10000, \"reserved\", [\"UE0\"])\n",
    "slot2 = Slot(1, 10000, 20000, \"reserved\", [\"UE0\"])\n",
    "schedule = {0: slot1, 1: slot2}\n",
    "base_schedule = Schedule(0, 20000, 2, schedule)\n",
    "print(base_schedule)\n",
    "\n",
    "# Create a UE\n",
    "ue = UE(0,{1: 0, 2: 1}, \"central control\", \"Mode 1\",  10)\n",
    "ue.generate_packets(base_schedule, [100]*10, [1]*10)\n",
    "print(ue)\n",
    "\n",
    "# Serve the packets\n",
    "ue.serve_packets(base_schedule)\n",
    "print(ue)\n",
    "\n",
    "latencies = ue.obtain_packet_latency()\n",
    "print(latencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e70d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters affecting how a packet is served: essentially MCS and latency from the Excel sheet\n",
    "# TODO: integrate MCS usage into the UE instead of having it outside\n",
    "# TODO: Create a simple CSV file of this\n",
    "\n",
    "\n",
    "# TODO: Remove the 67us from this that contains backoff \n",
    "parameters = {\n",
    "    \"setting 0\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 0,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 591.8\n",
    "    },\n",
    "    \"setting 1\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 0,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 964,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 1470.2\n",
    "    },\n",
    "    \"setting 2\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 0,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 2464,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 2953.4\n",
    "    },\n",
    "    \"setting 3\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 534.2\n",
    "    },\n",
    "    \"setting 4\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 964,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 980.6\n",
    "    },\n",
    "    \"setting 5\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 2464,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 1715\n",
    "    },\n",
    "    \"setting 6\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 519.8\n",
    "    },\n",
    "    \"setting 7\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 964,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 807.8\n",
    "    },\n",
    "    \"setting 8\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 2464,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 1311.8\n",
    "    },\n",
    "    \"setting 9\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 10,\n",
    "        \"delivery_latency\": 980.6\n",
    "    },\n",
    "    \"setting 10\": {\n",
    "        \"SNR\": 35,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 8,\n",
    "        \"PER\": 0.1170412, # PER corresponding to PSDU size 1000 as aggregation of 10 x 64 = 1000 B\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 10,\n",
    "        \"delivery_latency\": 563 \n",
    "    },\n",
    "    \"setting 11\": {\n",
    "        \"SNR\": 35,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 8,\n",
    "        \"PER\": 0.1170412, # PER corresponding to PSDU size 1000 as aggregation of 10 x 64 = 1000 B\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 10,\n",
    "        \"delivery_latency\": 563 \n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfd0d80",
   "metadata": {},
   "source": [
    "# Simulation 1: simulation of a UE with periodic slots \n",
    "\n",
    "- The base schedule is\n",
    "    - t0 - t1: UE 1\n",
    "    - t1 - t2: UE 2\n",
    "    - t2 - t3: UE 3\n",
    "    - t3 - t4: UE 1 and repeat\n",
    "- Packets are perfectly synchronized with the\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3753c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation with central control land periodic arrival of data\n",
    "\n",
    "setting = \"setting 9\"\n",
    "payload_size = parameters[setting][\"payload_size\"]*parameters[setting][\"aggregation\"]\n",
    "delivery_latency = parameters[setting][\"delivery_latency\"]\n",
    "PER = parameters[setting][\"PER\"]\n",
    "PER = 0.001\n",
    "# payload_size=1000\n",
    "# delivery_latency=5000\n",
    "\n",
    "num_UEs = 3\n",
    "UEs = [\"UE\" + str(i) for i in range(num_UEs)]\n",
    "num_packets_per_ue = 130  # Number of packets per UE for the whole period\n",
    "packet_sizes = [parameters[setting][\"payload_size\"]]*num_packets_per_ue\n",
    "priorities = [1]*num_packets_per_ue\n",
    "\n",
    "## Schedule parameters\n",
    "num_slots_per_UE = 100\n",
    "num_slots = num_slots_per_UE*num_UEs\n",
    "start_offset = 10 # microseconds\n",
    "end_time = start_offset\n",
    "slot_duration = 1000 # microseconds\n",
    "slots = {}\n",
    "\n",
    "\n",
    "# TODO: move the knowledge of how many packets there are to this part of the code\n",
    "# instead of keeping it in the UE class\n",
    "\n",
    "# Create a schedule\n",
    "start_time = start_offset\n",
    "for i in range(num_slots):\n",
    "    slots[i] = Slot(i, start_time, start_time + slot_duration, \"reserved\", [UEs[i%num_UEs]])\n",
    "    start_time += slot_duration\n",
    "schedule = Schedule(start_offset, start_time, num_slots, slots)\n",
    "\n",
    "# print(schedule)\n",
    "\n",
    "\n",
    "# Create UEs and packets\n",
    "UEs = {}\n",
    "for i in range(num_UEs):\n",
    "    UE_temp = UE(i, {1: 0, 2: 1}, \"central control\", \"Mode 2\",  num_packets_per_ue)\n",
    "    UE_temp.generate_packets(schedule, packet_sizes, priorities)\n",
    "    UEs[i] = UE_temp\n",
    "\n",
    "# for i in UEs:\n",
    "#     print(UEs[i])\n",
    "\n",
    "# Serve the packets\n",
    "for i in UEs:\n",
    "    UEs[i].serve_packets(schedule, payload_size=payload_size, delivery_latency=delivery_latency,\n",
    "                         PER=PER)\n",
    "\n",
    "# print(UEs[0])\n",
    "\n",
    "latencies = UEs[0].obtain_packet_latency()\n",
    "print(latencies)\n",
    "latencies = [latency for latency in latencies if latency is not None]\n",
    "\n",
    "# TODO: Make this more general i.e handle packet statuses directly instead of opearting under the \n",
    "# restrictions of this simulation\n",
    "num_packets_queued = num_packets_per_ue - len(latencies)\n",
    "print(f\"Number of packets not served: {num_packets_queued}\")\n",
    "\n",
    "# Plot a cdf of the latencies using the latencies variable above\n",
    "latencies = np.array(latencies)\n",
    "latencies = latencies/1000 # convert to milliseconds\n",
    "latencies = np.sort(latencies)\n",
    "yvals = (np.arange(len(latencies)) + 1)/float(len(latencies))\n",
    "plt.plot(latencies, yvals)\n",
    "plt.xlabel(\"Latency (ms)\")\n",
    "plt.ylabel(\"CDF\")\n",
    "title = (f\"Simulation 1 \\nUE_n_packets: {num_packets_per_ue}, \"\n",
    "         f\"num_UEs: {num_UEs},\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\")\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6282fe",
   "metadata": {},
   "source": [
    "## Simulation 2: simulating UEs with simple poisson arrival processes\n",
    "\n",
    "- TODO: Select packet sizes correctly\n",
    "- TODO: Select slot sizes correctly\n",
    "- TODO: Select PER correctly i.e modify the settings to have 10-3 PER instead of \n",
    "extrapolating\n",
    "- TODO: Change the latency-subtract the 67 us from the values to have it reflect \n",
    "the TSN case\n",
    "\n",
    "- Experiment-\n",
    "  - Determine a base schedule\n",
    "  - for a range of lambda values:\n",
    "    - Generate packets according to the base schedule for a UE\n",
    "    - Serve the packets\n",
    "    - Track n_packets_not_served, latencies of packets served, number of packets generated\n",
    "    - 99 percentile and average latency\n",
    "  - plot latency vs lambda\n",
    "  - Change base schedule repeat\n",
    "\n",
    "TODO: there should be some notion of the base schedule itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cce2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the simulation parameters\n",
    "\n",
    "results_directory_simulation = \"./results/simulation_2/\"\n",
    "\n",
    "setting = \"setting 9\"\n",
    "payload_size = parameters[setting][\"payload_size\"]*parameters[setting][\"aggregation\"]\n",
    "delivery_latency = parameters[setting][\"delivery_latency\"]\n",
    "PER = parameters[setting][\"PER\"]\n",
    "# PER = 0.1\n",
    "# payload_size=1000\n",
    "# delivery_latency=5000\n",
    "\n",
    "num_UEs = 3\n",
    "UEs = [\"UE\" + str(i) for i in range(num_UEs)]\n",
    "num_packets_per_ue = None  # Number of packets per UE for the whole period\n",
    "packet_sizes = [parameters[setting][\"payload_size\"]]\n",
    "priorities = [1]\n",
    "lambda_range = np.logspace(-4, -2, 30)\n",
    "UE_arrival = [\"Poisson\"]*num_UEs\n",
    "UE_serve_mode = [\"Mode 2\"]*num_UEs\n",
    "\n",
    "\n",
    "## Schedule parameters\n",
    "num_slots_per_UE = 1000\n",
    "num_slots = num_slots_per_UE*num_UEs\n",
    "start_offset = 10 # microseconds\n",
    "end_time = start_offset\n",
    "slot_duration = 4000 # microseconds\n",
    "slots = {}\n",
    "\n",
    "# Plot information\n",
    "percentile_to_plot = 99\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43bdda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a schedule, UEs and serve the packets\n",
    "\n",
    "\n",
    "# TODO: move the knowledge of how many packets there are to this part of the code\n",
    "# instead of keeping it in the UE class\n",
    "\n",
    "# Create a schedule\n",
    "start_time = start_offset\n",
    "for i in range(num_slots):\n",
    "    slots[i] = Slot(i, start_time, start_time + slot_duration, \"reserved\", [UEs[i%num_UEs]])\n",
    "    start_time += slot_duration\n",
    "schedule = Schedule(start_offset, start_time, num_slots, slots)\n",
    "\n",
    "end_time = start_time # Due to variable use while saving experiment parameters\n",
    "\n",
    "print(schedule)\n",
    "\n",
    "results_per_lambda = {}\n",
    "\n",
    "for lambda_value in lambda_range:\n",
    "# Create UEs and packets\n",
    "    UEs = {}\n",
    "    result = {}\n",
    "    # Creating a single UE is done to reduce time consumed as the behvaiour of other UEs does not\n",
    "    # affect the results of the simulation. 1 can be changed to num_UEs to simulate more UEs\n",
    "    for i in range(1): \n",
    "        # TODO: Move the UE creation parameters to the cell above?\n",
    "        UE_temp = UE(i, {1: 0, 2: 1}, UE_arrival[i], UE_serve_mode[i],  num_packets_per_ue)\n",
    "        UE_temp.set_poisson_lambda(lambda_value)\n",
    "        UE_temp.generate_packets(schedule, packet_sizes, priorities)\n",
    "        UEs[i] = UE_temp\n",
    "\n",
    "    # for i in UEs:\n",
    "    #     print(UEs[i])\n",
    "\n",
    "    # Serve the packets\n",
    "    for i in range(1):\n",
    "        UEs[i].serve_packets(schedule, payload_size=payload_size, delivery_latency=delivery_latency,\n",
    "                            PER=PER)\n",
    "\n",
    "    # for i in UEs:\n",
    "    #     print(UEs[i])\n",
    "\n",
    "    result[\"latencies\"] = UEs[0].obtain_packet_latency()\n",
    "    result[\"latencies_non_zero\"] = [latency for latency in result[\"latencies\"] if latency is not None]\n",
    "    result[\"num_packets_generated\"] = UEs[0].n_packets\n",
    "    result[\"num_packets_not_served\"] = result[\"num_packets_generated\"] - len(result[\"latencies_non_zero\"])\n",
    "    result[\"percentile_latency\"] = compute_percentile(result[\"latencies_non_zero\"], percentile_to_plot)\n",
    "    result[\"mean_latency\"] = np.mean(result[\"latencies_non_zero\"])\n",
    "    results_per_lambda[lambda_value] = result\n",
    "\n",
    "    # TODO: Check that the delivery times are always in ascending order\n",
    "    # TODO: check that the arrival times are always in ascending order\n",
    "\n",
    "    # TODO: Make this more general i.e handle packet statuses directly instead of opearting under the \n",
    "    # restrictions of this simulation\n",
    "    print(\"Num packets: \" + str(UEs[0].n_packets))\n",
    "    print(f\"Number of packets not served: {result['num_packets_not_served']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab354687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of number of packets generated vs lambda\n",
    "n_packets_generated = [results_per_lambda[lambda_value][\"num_packets_generated\"] \\\n",
    "                       for lambda_value in results_per_lambda]\n",
    "\n",
    "plt.plot(lambda_range, n_packets_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdffea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters and the results of the experiment to a file\n",
    "\n",
    "# Create a results directory folder using results_directory_simulation and the current time\n",
    "experiment_folder_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "results_directory_experiment = os.path.join(results_directory_simulation, experiment_folder_name)\n",
    "os.makedirs(results_directory_experiment, exist_ok=True)\n",
    "\n",
    "experiment_parameters = {\n",
    "    \"setting\": parameters[setting],\n",
    "    \"num_UEs\": num_UEs,\n",
    "    \"num_packets_per_ue\": num_packets_per_ue,\n",
    "    \"packet_sizes\": packet_sizes,\n",
    "    \"priorities\": priorities,\n",
    "    \"num_slots_per_UE\": num_slots_per_UE,\n",
    "    \"num_slots\": num_slots,\n",
    "    \"start_offset\": start_offset, # microseconds\n",
    "    \"end_time\": end_time,\n",
    "    \"slot_duration\": slot_duration,\n",
    "    \"percentile_to_plot\": percentile_to_plot,\n",
    "    \"lambda_range\": lambda_range,\n",
    "}\n",
    "\n",
    "# Write experiment_parameters_json to a json file with filename experiment_parameters.json\n",
    "\n",
    "experiment_parameters_json = json.dumps(experiment_parameters, indent=4, cls=NumpyEncoder)\n",
    "experiment_parameters_json_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                   \"experiment_parameters.json\")\n",
    "with open(experiment_parameters_json_filename, \"w\") as file:\n",
    "    file.write(experiment_parameters_json)\n",
    "\n",
    "\n",
    "experiment_parameters_pickle = {\n",
    "    \"schedule\": schedule,\n",
    "    \"UEs\": UEs,\n",
    "    \"results_per_lambda\": results_per_lambda,\n",
    "    \"experiment_parameters\": experiment_parameters\n",
    "}\n",
    "\n",
    "experiment_parameters_pickle_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                    \"experiment_parameters.pkl\")\n",
    "\n",
    "with open(experiment_parameters_pickle_filename, \"wb\") as file:\n",
    "    pickle.dump(experiment_parameters_pickle, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c812e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots: CDF of latencies, percentile latency vs lambda, mean latency vs lambda,\n",
    "# number of packets not served vs lambda\n",
    "\n",
    "# Plot cdf of latencies \n",
    "plt.figure()\n",
    "for lambda_value in lambda_range:\n",
    "    latencies = results_per_lambda[lambda_value][\"latencies_non_zero\"]\n",
    "    latencies = np.array(latencies)\n",
    "    latencies = latencies/1000 # convert to milliseconds\n",
    "    latencies = np.sort(latencies)\n",
    "    yvals = (np.arange(len(latencies)) + 1)/float(len(latencies))\n",
    "    plt.plot(latencies, yvals, label=f\"lambda: {lambda_value}\")\n",
    "plt.xlabel(\"Latency (ms)\")\n",
    "plt.ylabel(\"CDF\")\n",
    "title = (f\"Simulation 2 Latency vs lambda, \\n PER = {PER},\"\n",
    "         f\"num_UEs: {num_UEs},\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\")\n",
    "plt.title(title)\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"latency_cdf.png\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the percentile curve\n",
    "\n",
    "plt.figure()\n",
    "percentiles = []\n",
    "for lambda_value in lambda_range:\n",
    "    percentiles.append(results_per_lambda[lambda_value][\"percentile_latency\"])\n",
    "plt.plot(np.array(lambda_range)*(schedule.end_time - schedule.start_time), percentiles)\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.ylabel(str(percentile_to_plot) + \"percentile latency (us)\")\n",
    "\n",
    "title = (f\"Simulation 2 {percentile_to_plot} percentile latency vs lambda, \\n PER = {PER},\"\n",
    "         f\"num_UEs: {num_UEs},\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\")\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.text(0, percentiles[0], str(percentiles[0]), fontsize=12, verticalalignment='bottom')\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"percentile_latency.png\"))\n",
    "plt.show()\n",
    "\n",
    "print(schedule.end_time - schedule.start_time)\n",
    "\n",
    "# Plot the mean latency curve\n",
    "\n",
    "plt.figure()\n",
    "mean_latencies = []\n",
    "for lambda_value in lambda_range:\n",
    "    mean_latencies.append(results_per_lambda[lambda_value][\"mean_latency\"])\n",
    "plt.plot(lambda_range, mean_latencies)\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.ylabel(\"Mean latency (us)\")\n",
    "\n",
    "title = (f\"Simulation 2 mean latency vs lambda, \\n PER = {PER},\"\n",
    "         f\"num_UEs: {num_UEs},\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\")\n",
    "plt.title(title)\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"mean_latency.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Plot the number of packets not served\n",
    "\n",
    "plt.figure()\n",
    "n_packets_not_served = []\n",
    "for lambda_value in lambda_range:\n",
    "    n_packets_not_served.append(results_per_lambda[lambda_value][\"num_packets_not_served\"])\n",
    "plt.plot(lambda_range, n_packets_not_served)\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.ylabel(\"Number of packets not served\")\n",
    "\n",
    "title = (f\"Simulation 2 Number of packets queued vs lambda, \\n PER = {PER},\"\n",
    "         f\"num_UEs: {num_UEs},\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\")\n",
    "plt.title(title)\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"n_packets_not_served.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1ea427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting inter-arrival times and arrival times\n",
    "\n",
    "arrival_times = []\n",
    "for packet in UEs[0].packets:\n",
    "    arrival_times.append(packet.arrival_time)\n",
    "\n",
    "# plot histogram of arrival times\n",
    "plt.hist(arrival_times, bins=100)\n",
    "plt.xlabel(\"Arrival time (us)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Arrival time histogram\")\n",
    "plt.show()\n",
    "\n",
    "arrival_times = np.array(arrival_times)\n",
    "inter_arrival_times = np.diff(arrival_times)\n",
    "plt.hist(inter_arrival_times, bins=100)\n",
    "plt.xlabel(\"Inter-arrival time (us)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Inter-arrival time histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5edf56b",
   "metadata": {},
   "source": [
    "# Testing the contention code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c85f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and testing a contention slot\n",
    "\n",
    "setting = \"setting 9\"\n",
    "payload_size = 1000 # parameters[setting][\"payload_size\"]*parameters[setting][\"aggregation\"]\n",
    "delivery_latency = 500 # parameters[setting][\"delivery_latency\"]\n",
    "PER = parameters[setting][\"PER\"]\n",
    "PER = 0\n",
    "# payload_size=1000\n",
    "# delivery_latency=5000\n",
    "\n",
    "num_UEs = 3\n",
    "UE_names = [\"UE\" + str(i) for i in range(num_UEs)]\n",
    "num_packets_per_ue = 130  # Number of packets per UE for the whole period\n",
    "packet_sizes = [100]*num_packets_per_ue\n",
    "priorities = [1]*num_packets_per_ue\n",
    "\n",
    "## Schedule parameters\n",
    "num_slots_per_UE = 100\n",
    "# num_slots = num_slots_per_UE*num_UEs\n",
    "num_slots = 1\n",
    "start_offset = 10 # microseconds\n",
    "end_time = start_offset\n",
    "slot_duration = 10000 # microseconds\n",
    "slots = {}\n",
    "\n",
    "\n",
    "# TODO: move the knowledge of how many packets there are to this part of the code\n",
    "# instead of keeping it in the UE class\n",
    "\n",
    "# Create a schedule\n",
    "# start_time = start_offset\n",
    "# for i in range(num_slots):\n",
    "#     slots[i] = Slot(i, start_time, start_time + slot_duration, \"reserved\", [UEs[i%num_UEs]])\n",
    "#     start_time += slot_duration\n",
    "# schedule = Schedule(start_offset, start_time, num_slots, slots)\n",
    "\n",
    "slots[0] = Slot(0, start_offset, start_offset + slot_duration, \"contention\", UE_names)\n",
    "schedule = Schedule(start_offset, start_offset + slot_duration, num_slots, slots)\n",
    "print(schedule)\n",
    "\n",
    "\n",
    "# Create UEs and packets\n",
    "UEs = {}\n",
    "for i in range(num_UEs):\n",
    "    UE_temp = UE(i, {1: 0, 2: 1}, \"central control\", \"Mode 2\",  num_packets_per_ue)\n",
    "    UE_temp.generate_packets(schedule, packet_sizes, priorities)\n",
    "    UEs[UE_names[i]] = UE_temp\n",
    "\n",
    "for i in UEs:\n",
    "    print(UEs[i])\n",
    "\n",
    "# Serve the packets\n",
    "# for i in UEs:\n",
    "#     UEs[i].serve_packets(schedule, payload_size=payload_size, delivery_latency=delivery_latency,\n",
    "#                          PER=PER)\n",
    "    \n",
    "test_network = Network(10, 30, UEs)\n",
    "test_network.serve_packets(schedule, \"Mode 3\", \n",
    "                           payload_size = {\"reserved\": payload_size, \"contention\": payload_size},\n",
    "                           delivery_latency = {\"reserved\": delivery_latency, \"contention\": delivery_latency},\n",
    "                           PER = {\"reserved\": PER, \"contention\": PER})\n",
    "\n",
    "# print(UEs[0])\n",
    "\n",
    "latencies = UEs[\"UE0\"].obtain_packet_latency()\n",
    "print(latencies)\n",
    "latencies = [latency for latency in latencies if latency is not None]\n",
    "\n",
    "# TODO: Make this more general i.e handle packet statuses directly instead of opearting under the \n",
    "# restrictions of this simulation\n",
    "num_packets_queued = num_packets_per_ue - len(latencies)\n",
    "print(f\"Number of packets not served: {num_packets_queued}\")\n",
    "\n",
    "# Plot a cdf of the latencies using the latencies variable above\n",
    "latencies = np.array(latencies)\n",
    "latencies = latencies/1000 # convert to milliseconds\n",
    "latencies = np.sort(latencies)\n",
    "yvals = (np.arange(len(latencies)) + 1)/float(len(latencies))\n",
    "plt.plot(latencies, yvals)\n",
    "plt.xlabel(\"Latency (ms)\")\n",
    "plt.ylabel(\"CDF\")\n",
    "title = (f\"Simulation 1 \\nUE_n_packets: {num_packets_per_ue}, \"\n",
    "         f\"num_UEs: {num_UEs},\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\")\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97532162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print contention winners\n",
    "\n",
    "for value in test_network.selected_UEs:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41af1d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print a UE to see that the packet behaviour matches expected contention behaviour\n",
    "print(UEs[\"UE2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f0c803",
   "metadata": {},
   "source": [
    "# Simulation 3: poisson arrivals and contention vs Simulation 2's base schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89544487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the simulation parameters\n",
    "\n",
    "results_directory_simulation = \"./results/simulation_3/\"\n",
    "\n",
    "setting_reserved = \"setting 9\"\n",
    "setting_contention = \"setting 10\"\n",
    "payload_size = {\"reserved\": parameters[setting_reserved][\"payload_size\"]*parameters[setting_reserved][\"aggregation\"], \n",
    "                \"contention\": parameters[setting_contention][\"payload_size\"]*parameters[setting_contention][\"aggregation\"]}\n",
    "delivery_latency = {\"reserved\": parameters[setting_reserved][\"delivery_latency\"],\n",
    "                    \"contention\": parameters[setting_contention][\"delivery_latency\"]}\n",
    "PER = {\"reserved\":  parameters[setting_reserved][\"PER\"], \n",
    "       \"contention\":  parameters[setting_contention][\"PER\"]}\n",
    "\n",
    "## Just an experiment to see how PER affects performance\n",
    "PER[\"contention\"] = 0\n",
    "\n",
    "num_UEs = 3\n",
    "UE_names = [\"UE\" + str(i) for i in range(num_UEs)]\n",
    "num_packets_per_ue = None  # Number of packets per UE for the whole period\n",
    "packet_sizes = [parameters[setting_reserved][\"payload_size\"]] # TODO: Both have same packet size, but what if they don't?\n",
    "priorities = [1]\n",
    "lambda_range = np.logspace(-4, -2.5, 10)\n",
    "lambda_range = [10**(-2.5)]\n",
    "UE_arrival = [\"Poisson\"]*num_UEs\n",
    "UE_serve_mode = [\"Mode 2\"]*num_UEs\n",
    "\n",
    "\n",
    "## Schedule parameters for reserved base schedule\n",
    "num_slots_per_UE = 1000\n",
    "num_slots = num_slots_per_UE*num_UEs\n",
    "start_offset = 10 # microseconds\n",
    "end_time = start_offset\n",
    "slot_duration = delivery_latency[\"reserved\"] + 200 # microseconds\n",
    "\n",
    "\n",
    "# Network properties\n",
    "# Obtained from the sheet\n",
    "wifi_slot_time = 9 # microseconds\n",
    "DIFS = 34 # microseconds\n",
    "\n",
    "\n",
    "\n",
    "# Plot information\n",
    "percentile_to_plot = 99\n",
    "num_iterations_contention = 1\n",
    "mode_contention = \"Mode 3\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08287ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a schedule, UEs and serve the packets\n",
    "\n",
    "\n",
    "# TODO: move the knowledge of how many packets there are to this part of the code\n",
    "# instead of keeping it in the UE class\n",
    "\n",
    "# Create a schedule\n",
    "slots = {}\n",
    "start_time = start_offset\n",
    "for i in range(num_slots):\n",
    "    slots[i] = Slot(i, start_time, start_time + slot_duration, \"reserved\", [UE_names[i%num_UEs]])\n",
    "    start_time += slot_duration\n",
    "schedule_reserved = Schedule(start_offset, start_time, num_slots, slots)\n",
    "\n",
    "end_time = start_time # Due to variable use while saving experiment parameters\n",
    "\n",
    "slots_temp = {}\n",
    "slots_temp[0] = Slot(0, start_offset, end_time, \"contention\", UE_names)\n",
    "schedule_contention = Schedule(start_offset, end_time, 1, slots_temp)\n",
    "\n",
    "\n",
    "# print(schedule_reserved)\n",
    "print(schedule_contention)\n",
    "\n",
    "results_per_lambda = {}\n",
    "results_per_lambda_contention = {}\n",
    "results_per_lambda_per_iteration_contention = {}\n",
    "count = 0\n",
    "\n",
    "for lambda_value in lambda_range:\n",
    "    count = count + 1\n",
    "    print(\"\\nLambda value: \" + str(lambda_value), \"Count: \" + str(count))\n",
    "# Create UEs and packets\n",
    "    UEs = {}\n",
    "    \n",
    "    result_contention = {}\n",
    "    # Creating a single UE is done to reduce time consumed as the behvaiour of other UEs does not\n",
    "    # affect the results of the simulation. 1 can be changed to num_UEs to simulate more UEs\n",
    "    for i in range(num_UEs): \n",
    "        # TODO: Move the UE creation parameters to the cell above?\n",
    "        UE_temp = UE(i, {1: 0, 2: 1}, UE_arrival[i], UE_serve_mode[i],  num_packets_per_ue)\n",
    "        UE_temp.set_poisson_lambda(lambda_value)\n",
    "        UE_temp.generate_packets(schedule_reserved, packet_sizes, priorities)\n",
    "        UEs[UE_names[i]] = UE_temp\n",
    "    \n",
    "    UEs_contention = copy.deepcopy(UEs)\n",
    "\n",
    "    # for i in UEs:\n",
    "    #     print(UEs[i])\n",
    "\n",
    "    # Serve the packets\n",
    "    # Serving only one UE to reduce time taken to run code\n",
    "    for i in range(1):\n",
    "        UEs[UE_names[i]].serve_packets(schedule_reserved, \n",
    "                                       payload_size=payload_size[\"reserved\"], \n",
    "                                       delivery_latency=delivery_latency[\"reserved\"],\n",
    "                                       PER=PER[\"reserved\"])\n",
    "\n",
    "    # for i in UEs:\n",
    "    #     print(UEs[i])\n",
    "    result = {}\n",
    "    result[\"latencies\"] = UEs[\"UE0\"].obtain_packet_latency()\n",
    "    result[\"latencies_non_zero\"] = [latency for latency in result[\"latencies\"] if latency is not None]\n",
    "    result[\"num_packets_generated\"] = UEs[\"UE0\"].n_packets\n",
    "    result[\"num_packets_not_served\"] = result[\"num_packets_generated\"] - len(result[\"latencies_non_zero\"])\n",
    "    result[\"percentile_latency\"] = compute_percentile(result[\"latencies_non_zero\"], percentile_to_plot)\n",
    "    result[\"mean_latency\"] = np.mean(result[\"latencies_non_zero\"])\n",
    "    result[\"UEs\"] = UEs\n",
    "    results_per_lambda[lambda_value] = result\n",
    "\n",
    "    # TODO: Check that the delivery times are always in ascending order\n",
    "    # TODO: check that the arrival times are always in ascending order\n",
    "\n",
    "    # TODO: Make this more general i.e handle packet statuses directly instead of opearting under the \n",
    "    # restrictions of this simulation\n",
    "    print(\"Num packets, reserved: \" + str(UEs[\"UE0\"].n_packets))\n",
    "    print(f\"Number of packets not served, reserved: {result['num_packets_not_served']}\")\n",
    "\n",
    "    # Serve the packets with contention\n",
    "    mean_latencies_contention = []\n",
    "    percentile_latencies_contention = []\n",
    "    n_packets_unserved_contention = []\n",
    "    results_iteration = {}\n",
    "    \n",
    "\n",
    "    for i in range(num_iterations_contention):\n",
    "        print(\"Contention iteration: \" + str(i))\n",
    "        UEs_contention_temp = copy.deepcopy(UEs_contention)\n",
    "\n",
    "        test_network = Network(wifi_slot_time, DIFS, UEs_contention_temp)\n",
    "        test_network.serve_packets(schedule_contention, mode_contention, \n",
    "                                    payload_size = payload_size,\n",
    "                                    delivery_latency = delivery_latency,\n",
    "                                    PER = PER)\n",
    "        \n",
    "        # TODO: store results for multiple UEs\n",
    "        result_contention_temp = {} \n",
    "        result_contention_temp[\"latencies\"] = UEs_contention_temp[\"UE0\"].obtain_packet_latency()\n",
    "        result_contention_temp[\"latencies_non_zero\"] = \\\n",
    "            [latency for latency in result_contention_temp[\"latencies\"] if latency is not None]\n",
    "        result_contention_temp[\"num_packets_generated\"] = \\\n",
    "            UEs_contention_temp[\"UE0\"].n_packets # TODO: Change this to UE_contention_temp\n",
    "        result_contention_temp[\"num_packets_not_served\"] = \\\n",
    "            result_contention_temp[\"num_packets_generated\"] - \\\n",
    "            len(result_contention_temp[\"latencies_non_zero\"])\n",
    "        result_contention_temp[\"percentile_latency\"] = \\\n",
    "            compute_percentile(result_contention_temp[\"latencies_non_zero\"], percentile_to_plot)\n",
    "        # print(\"percentile latency\", result_contention_temp[\"percentile_latency\"])\n",
    "        result_contention_temp[\"mean_latency\"] = np.mean(result_contention_temp[\"latencies_non_zero\"])\n",
    "        # print(\"mean_latency\", result_contention_temp[\"mean_latency\"])\n",
    "        result_contention_temp[\"UEs\"] = UEs_contention_temp\n",
    "\n",
    "        mean_latencies_contention.append(result_contention_temp[\"mean_latency\"])\n",
    "        percentile_latencies_contention.append(result_contention_temp[\"percentile_latency\"])\n",
    "        n_packets_unserved_contention.append(result_contention_temp[\"num_packets_not_served\"])\n",
    "\n",
    "        # print(mean_latencies_contention)\n",
    "        # print(percentile_latencies_contention)\n",
    "        # print(\"results_contention_temp\", result_contention_temp)\n",
    "\n",
    "        results_iteration[i] = result_contention_temp\n",
    "    # for key in results_iteration:\n",
    "    #     print(\"results_iteration \" + str(key), results_iteration[key])\n",
    "\n",
    "    # TODO: Scale to multiple UEs, currently you're extracting the results only for one UE,\n",
    "    # but you should be extracting the results for all UEs\n",
    "    \n",
    "\n",
    "    results_per_lambda_per_iteration_contention[lambda_value] = results_iteration\n",
    "    results_per_lambda_contention[lambda_value] = copy.deepcopy(results_iteration[0])\n",
    "    results_per_lambda_contention[lambda_value][\"mean_latency\"] = np.mean(mean_latencies_contention)\n",
    "    results_per_lambda_contention[lambda_value][\"mean_latency_std\"] = \\\n",
    "                                                    np.std(mean_latencies_contention)\n",
    "    results_per_lambda_contention[lambda_value][\"percentile_latency\"] = \\\n",
    "                                                    np.mean(percentile_latencies_contention)\n",
    "    results_per_lambda_contention[lambda_value][\"percentile_latency_std\"] = \\\n",
    "                                                    np.std(percentile_latencies_contention)\n",
    "    results_per_lambda_contention[lambda_value][\"num_packets_not_served\"] = \\\n",
    "                                                    np.mean(n_packets_unserved_contention)\n",
    "    results_per_lambda_contention[lambda_value][\"num_packets_not_served_std\"] = \\\n",
    "                                                    np.std(n_packets_unserved_contention)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ue in UEs_contention:\n",
    "#     print(UEs_contention[ue])\n",
    "for ue in UEs_contention_temp:\n",
    "    print(UEs_contention_temp[ue])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df37c1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the contents of the results_per_lambda_per_iteration_contention variable\n",
    "\n",
    "for key in results_per_lambda_per_iteration_contention:\n",
    "    print(\"key\", key)\n",
    "    for key2 in results_per_lambda_per_iteration_contention[key]:\n",
    "        print(\"key2\", key2)\n",
    "        # print(results_per_lambda_per_iteration_contention[key][key2])\n",
    "        for key3 in results_per_lambda_per_iteration_contention[key][key2]:\n",
    "            print(\"key3\", key3, results_per_lambda_per_iteration_contention[key][key2][key3])\n",
    "\n",
    "\n",
    "\n",
    "# print number of bytes of results_per_lambda_per_iteration_contention\n",
    "print(\"Number of bytes: \" + str(sys.getsizeof(results_per_lambda_per_iteration_contention)))\n",
    "print(mean_latencies_contention)\n",
    "print(percentile_latencies_contention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7456db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the contents fo the results_per_lambda_contention variable\n",
    "\n",
    "for key in results_per_lambda_contention:\n",
    "    print(\"key\", key)\n",
    "    for key2 in results_per_lambda_contention[key]:\n",
    "        print(\"key2\", key2, results_per_lambda_contention[key][key2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9f956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a results directory folder using results_directory_simulation and the current time\n",
    "experiment_folder_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "results_directory_experiment = os.path.join(results_directory_simulation, experiment_folder_name)\n",
    "os.makedirs(results_directory_experiment, exist_ok=True)\n",
    "# Plots: CDF of latencies, percentile latency vs lambda, mean latency vs lambda,\n",
    "# number of packets not served vs lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b6222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters and the results of the experiment to a file\n",
    "\n",
    "experiment_parameters = {\n",
    "    \"setting_reserved\": parameters[setting_reserved],\n",
    "    \"setting_contention\": parameters[setting_contention],\n",
    "    \"num_UEs\": num_UEs,\n",
    "    \"num_packets_per_ue\": num_packets_per_ue,\n",
    "    \"packet_sizes\": packet_sizes,\n",
    "    \"priorities\": priorities,\n",
    "    \"UE_arrival\": UE_arrival,\n",
    "    \"UE_serve_mode\": UE_serve_mode,\n",
    "    \"num_slots_per_UE\": num_slots_per_UE,\n",
    "    \"num_slots\": num_slots,\n",
    "    \"start_offset\": start_offset, # microseconds\n",
    "    \"end_time\": end_time,\n",
    "    \"slot_duration\": slot_duration,\n",
    "    \"percentile_to_plot\": percentile_to_plot,\n",
    "    \"wifi_slot_time\": wifi_slot_time,\n",
    "    \"DIFS\": DIFS,\n",
    "    \"num_iterations_contention\": num_iterations_contention,\n",
    "    \"contention_mode\": mode_contention,\n",
    "    \"lambda_range\": lambda_range,\n",
    "}\n",
    "\n",
    "# Write experiment_parameters_json to a json file with filename experiment_parameters.json\n",
    "\n",
    "experiment_parameters_json = json.dumps(experiment_parameters, indent=4, cls=NumpyEncoder)\n",
    "experiment_parameters_json_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                   \"experiment_parameters.json\")\n",
    "with open(experiment_parameters_json_filename, \"w\") as file:\n",
    "    file.write(experiment_parameters_json)\n",
    "\n",
    "\n",
    "experiment_parameters_pickle = {\n",
    "    \"schedule_reserved\": schedule_reserved,\n",
    "    \"schedule_contention\": schedule_contention,\n",
    "    \"UEs\": UEs,\n",
    "    \"results_per_lambda\": results_per_lambda,\n",
    "    \"results_per_lambda_contention\": results_per_lambda_contention,\n",
    "    \"results_per_lambda_per_iteration_contention\": results_per_lambda_per_iteration_contention,\n",
    "    \"experiment_parameters\": experiment_parameters\n",
    "}\n",
    "\n",
    "experiment_parameters_pickle_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                    \"experiment_parameters.pkl\")\n",
    "\n",
    "with open(experiment_parameters_pickle_filename, \"wb\") as file:\n",
    "    pickle.dump(experiment_parameters_pickle, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22e507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data from the simulation\n",
    "\n",
    "# Plot cdf of latencies \n",
    "plt.figure()\n",
    "for lambda_value in lambda_range:\n",
    "    latencies = results_per_lambda[lambda_value][\"latencies_non_zero\"]\n",
    "    latencies = np.array(latencies)\n",
    "    latencies = latencies/1000 # convert to milliseconds\n",
    "    latencies = np.sort(latencies)\n",
    "    yvals = (np.arange(len(latencies)) + 1)/float(len(latencies))\n",
    "    plt.plot(latencies, yvals, label=f\"lambda: {lambda_value}\")\n",
    "plt.xlabel(\"Latency (ms)\")\n",
    "plt.ylabel(\"CDF\")\n",
    "title = (f\"Simulation 3 Latency vs lambda reserved, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs},\\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \\n\"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\"\n",
    "         )\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"latency_cdf.png\"))\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "for lambda_value in lambda_range:\n",
    "    latencies = results_per_lambda_contention[lambda_value][\"latencies_non_zero\"]\n",
    "    latencies = np.array(latencies)\n",
    "    latencies = latencies/1000 # convert to milliseconds\n",
    "    latencies = np.sort(latencies)\n",
    "    yvals = (np.arange(len(latencies)) + 1)/float(len(latencies))\n",
    "    plt.plot(latencies, yvals, label=f\"lambda: {lambda_value}\")\n",
    "plt.xlabel(\"Latency (ms)\")\n",
    "plt.ylabel(\"CDF\")\n",
    "title = (f\"Simulation 3 Latency vs lambda contention#, \\n PER = {PER},\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \\n\"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\"\n",
    "         )\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"latency_cdf_contention.png\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Plot the percentile curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "percentiles = []\n",
    "for lambda_value in lambda_range:\n",
    "    percentiles.append(results_per_lambda[lambda_value][\"percentile_latency\"])\n",
    "plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time), \\\n",
    "         percentiles, \".-\", label = \"reserved\")\n",
    "\n",
    "percentiles_contention = []\n",
    "percentiles_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    percentiles_contention.append(results_per_lambda_contention[lambda_value][\"percentile_latency\"])\n",
    "    percentiles_contention_std.append(\\\n",
    "        results_per_lambda_contention[lambda_value][\"percentile_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time), \\\n",
    "        percentiles_contention, percentiles_contention_std, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda*schedule_duration (us)\")\n",
    "plt.ylabel(str(percentile_to_plot) + \"percentile latency (us)\")\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "title = (f\"Simulation 3 {percentile_to_plot} percentile latency vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \\n\"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.text(0, percentiles[0], str(np.round(percentiles[0],2)), fontsize=12, verticalalignment='bottom')\n",
    "plt.text(0, percentiles_contention[0] + 10000, str(np.round(percentiles_contention[0],2)), \\\n",
    "         fontsize=12, verticalalignment='bottom')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"percentile_latency.png\"))\n",
    "plt.show()\n",
    "\n",
    "print(schedule_reserved.end_time - schedule_reserved.start_time)\n",
    "print(schedule_contention.end_time - schedule_contention.start_time)\n",
    "\n",
    "\n",
    "# Plot the mean latency curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "mean_latencies = []\n",
    "for lambda_value in lambda_range:\n",
    "    mean_latencies.append(results_per_lambda[lambda_value][\"mean_latency\"])\n",
    "plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time),\\\n",
    "         mean_latencies, \".-\", label = \"reserved\")\n",
    "\n",
    "mean_latencies_contention = []\n",
    "mean_latencies_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    mean_latencies_contention.append(results_per_lambda_contention[lambda_value][\"mean_latency\"])\n",
    "    mean_latencies_contention_std.append(\\\n",
    "        results_per_lambda_contention[lambda_value][\"mean_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time),\\\n",
    "        mean_latencies_contention, mean_latencies_contention_std, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "\n",
    "plt.text(0, mean_latencies[0], str(np.round(mean_latencies[0],2)), fontsize=12, verticalalignment='top')\n",
    "plt.text(0, mean_latencies_contention[0], str(np.round(mean_latencies_contention[0],2)), \\\n",
    "         fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"lambda*schedule_duration\")\n",
    "plt.ylabel(\"Mean latency (us)\")\n",
    "\n",
    "plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 mean latency vs lambda, \\n PER = {PER}, \\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \\n\"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\")\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"mean_latency.png\"))\n",
    "plt.show()\n",
    "\n",
    "# Plot the number of packets not served\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "n_packets_not_served = []\n",
    "for lambda_value in lambda_range:\n",
    "    n_packets_not_served.append(results_per_lambda[lambda_value][\"num_packets_not_served\"])\n",
    "plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time), \\\n",
    "         n_packets_not_served, label = \"reserved\")\n",
    "\n",
    "\n",
    "n_packets_not_served_contention = []\n",
    "n_packets_not_served_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    n_packets_not_served_contention.append(results_per_lambda_contention[lambda_value][\"num_packets_not_served\"])\n",
    "    n_packets_not_served_contention_std.append(results_per_lambda_contention[lambda_value][\"num_packets_not_served_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time), \\\n",
    "         n_packets_not_served_contention, n_packets_not_served_contention_std,  label = \"contention\")\n",
    "\n",
    "plt.xlabel(\"lambda*schedule_duration\")\n",
    "plt.ylabel(\"Number of packets not served\")\n",
    "\n",
    "title = (f\"Simulation 3 Number of packets queued vs lambda, \\n PER = {PER}, \\n\"\n",
    "         f\"num_UEs: {num_UEs},\\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \\n\"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\")\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"n_packets_not_served.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80efdc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
