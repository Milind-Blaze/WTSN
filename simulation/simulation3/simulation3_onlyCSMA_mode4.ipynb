{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation 3 with dynamic aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulating the WTSN setting\n",
    "\n",
    "Authors: Milind Kumar Vaddiraju, ChatGPT, Copilot\n",
    "\"\"\"\n",
    "\n",
    "# Necessary imports\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import json\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "import time\n",
    "\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "from network_classes import *\n",
    "from utils import *\n",
    "\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_filename = \"../wireless_parameters/wireless_parameters_DL_MU_964B_80MHz.json\"\n",
    "with open(parameters_filename, 'r') as f:\n",
    "    parameters = json.load(f)\n",
    "print(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the simulation parameters\n",
    "\n",
    "results_directory_simulation = \"../results/simulation_3/\"\n",
    "config_file = \"No config file\"\n",
    "\n",
    "setting_reserved = \"setting 0\"\n",
    "setting_contention = \"setting 6\"\n",
    "payload_size = {\"reserved\": parameters[setting_reserved][\"payload_size\"]*parameters[setting_reserved][\"aggregation\"], \n",
    "                \"contention\": parameters[setting_contention][\"payload_size\"]*parameters[setting_contention][\"aggregation\"]}\n",
    "delivery_latency = {\"reserved\": parameters[setting_reserved][\"delivery_latency\"],\n",
    "                    \"contention\": parameters[setting_contention][\"delivery_latency\"]}\n",
    "PER = {\"reserved\":  parameters[setting_reserved][\"PER\"], \n",
    "       \"contention\":  parameters[setting_contention][\"PER\"]}\n",
    "aggregation_limit = 104\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_UEs = 10\n",
    "UE_names = [\"UE\" + str(i) for i in range(num_UEs)]\n",
    "num_packets_per_ue = None  # Number of packets per UE for the whole period\n",
    "packet_sizes = [parameters[setting_reserved][\"payload_size\"]] # TODO: Both have same packet size, but what if they don't?\n",
    "priorities = [1]\n",
    "# lambda_range = np.logspace(-4.5, -3, 20)\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3, 10), np.logspace(-3, -2.2, 5)))\n",
    "# For 10 UEs\n",
    "# lambda_range = np.logspace(-4.5, -3.765, 15)\n",
    "# For aggregation 5\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3.72, 6), np.logspace(-3.61, -3.43, 9)))\n",
    "# For aggregation 10\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3.83, 5), np.logspace(-3.75, -3.35, 10)))\n",
    "lambda_range = np.concatenate((np.logspace(-4.5, -3.83, 5), np.logspace(-3.75, -2.82, 10))) # testing code speed\n",
    "# lambda_range = [lambda_range[-1]]\n",
    "# For aggregation 2\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3.8, 5), np.logspace(-3.745, -3.4, 5)))\n",
    "# lambda_range = [lambda_range[-1]]\n",
    "# For 3 UEs\n",
    "# lambda_range = np.logspace(-4.5, -3.26, 15)\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3.43, 8), np.logspace(-3.34, -3.26, 7)))\n",
    "# lambda_range = [10**(-4.5)]\n",
    "# For 5 UEs\n",
    "# lambda_range = np.logspace(-4.5, -3.45, 10)\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3.56, 5), np.logspace(-3.5, -3.45, 5)))\n",
    "# lambda_range = [lambda_range[-1]]\n",
    "# For 1 UE\n",
    "# lambda_range = np.logspace(-4.5, -3.5, 10)\n",
    "lambda_original = copy.deepcopy(lambda_range)\n",
    "UE_arrival = [\"Poisson\"]*num_UEs\n",
    "UE_serve_mode = [\"Mode 4\"]*num_UEs\n",
    "num_iterations_arrival = 1\n",
    "CWmin = 15\n",
    "CWmax = 1023\n",
    "\n",
    "\n",
    "## Schedule parameters for reserved base schedule\n",
    "start_offset = 10 # microseconds\n",
    "end_time = 10*10**6 + start_offset # microseconds\n",
    "\n",
    "\n",
    "# Network properties\n",
    "# Obtained from the sheet\n",
    "wifi_slot_time = 9 # microseconds\n",
    "DIFS = 34 # microseconds\n",
    "\n",
    "\n",
    "\n",
    "# Plot information\n",
    "percentile_to_plot = 99\n",
    "num_iterations_contention = [1]*len(lambda_range)\n",
    "mode_contention = \"Mode 4\" \n",
    "advance_time = 10 # microseconds\n",
    "debug_mode = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(delivery_latency[\"contention\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_iterations_contention)\n",
    "assert len(num_iterations_contention) == len(lambda_range), \"Lengths not equal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config_file = \"../experiment_configs/simulation3/10UEs_bus_size_2.json\"\n",
    "config_file = \"../experiment_configs/1UE_dummy.json\"\n",
    "with open(config_file, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Set the simulation parameters\n",
    "\n",
    "results_directory_simulation = config[\"results_directory_simulation\"]\n",
    "\n",
    "setting_reserved = config[\"setting_reserved\"]\n",
    "setting_contention = config[\"setting_contention\"]\n",
    "payload_size = {\"reserved\": parameters[setting_reserved][\"payload_size\"]*parameters[setting_reserved][\"aggregation\"], \n",
    "                \"contention\": parameters[setting_contention][\"payload_size\"]*parameters[setting_contention][\"aggregation\"]}\n",
    "delivery_latency = {\"reserved\": parameters[setting_reserved][\"delivery_latency\"],\n",
    "                    \"contention\": parameters[setting_contention][\"delivery_latency\"]}\n",
    "PER = {\"reserved\":  parameters[setting_reserved][\"PER\"], \n",
    "       \"contention\":  parameters[setting_contention][\"PER\"]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_UEs = config[\"num_UEs\"]\n",
    "UE_names = [\"UE\" + str(i) for i in range(num_UEs)]\n",
    "num_packets_per_ue = config[\"num_packets_per_ue\"]  # Number of packets per UE for the whole period\n",
    "packet_sizes = [parameters[setting_reserved][\"payload_size\"]] # TODO: Both have same packet size, but what if they don't?\n",
    "priorities = [1]\n",
    "# lambda_range = np.logspace(-4.5, -3, 20)\n",
    "# lambda_range = np.concatenate((np.logspace(-4.5, -3, 10), np.logspace(-3, -2.2, 5)))\n",
    "# For 10 UEs\n",
    "\n",
    "lambda_range = np.array([])\n",
    "for lambda_range_parameter in config[\"lambda_range_parameters\"]:\n",
    "    lambda_range_low = lambda_range_parameter[0]\n",
    "    lambda_range_high = lambda_range_parameter[1]\n",
    "    num_lambda_values = lambda_range_parameter[2]\n",
    "    lambda_range = np.concatenate((lambda_range, \\\n",
    "                                   np.logspace(lambda_range_low, lambda_range_high, num_lambda_values)))\n",
    "\n",
    "\n",
    "# lambda_range = [10**(-4.5)]\n",
    "lambda_original = copy.deepcopy(lambda_range)\n",
    "UE_arrival = [\"Poisson\"]*num_UEs\n",
    "UE_serve_mode = [\"Mode 2\"]*num_UEs\n",
    "num_iterations_arrival = config[\"num_iterations_arrival\"]\n",
    "CWmin = config[\"CWmin\"]\n",
    "CWmax = config[\"CWmax\"]\n",
    "\n",
    "\n",
    "## Schedule parameters for reserved base schedule\n",
    "start_offset = config[\"start_offset\"] # microseconds\n",
    "end_time = config[\"duration\"] + start_offset # microseconds\n",
    "\n",
    "\n",
    "# Network properties\n",
    "# Obtained from the sheet\n",
    "wifi_slot_time = config[\"wifi_slot_time\"] # microseconds\n",
    "DIFS = config[\"DIFS\"] # microseconds\n",
    "\n",
    "\n",
    "\n",
    "# Plot information\n",
    "percentile_to_plot = config[\"percentile_to_plot\"]\n",
    "num_iterations_contention = config[\"num_iterations_contention\"]\n",
    "mode_contention = config[\"mode_contention\"] \n",
    "advance_time = config[\"advance_time\"] # microseconds\n",
    "debug_mode = False\n",
    "\n",
    "\n",
    "assert len(num_iterations_contention) == len(lambda_range), \"Lengths not equal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_directory_simulation = \"../results/simulation_3/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(lambda_range) == len(num_iterations_contention), \"Lengths not equal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a schedule, UEs and serve the packets, not integrated with result extraction\n",
    "\n",
    "slots_temp = {}\n",
    "slots_temp[0] = Slot(0, start_offset, end_time, \"contention\", UE_names)\n",
    "schedule_contention = Schedule(start_offset, end_time, 1, slots_temp)\n",
    "\n",
    "\n",
    "# print(schedule_reserved)\n",
    "print(schedule_contention)\n",
    "\n",
    "results_per_lambda_contention = {}\n",
    "\n",
    "count = 0\n",
    "\n",
    "execution_start_time = time.time()\n",
    "\n",
    "for lambda_value in lambda_range:\n",
    "    \n",
    "    print(\"\\n###### Lambda value: \" + str(lambda_value), \", Count: \" + str(count), \"######\")\n",
    "    \n",
    "    \n",
    "    results_per_lambda_per_iteration_contention = {}\n",
    "    for num_arrival_iteration in range(num_iterations_arrival):\n",
    "        print(\"\\nArrival iteration: \" + str(num_arrival_iteration))\n",
    "        # Create UEs and packets\n",
    "        \n",
    "        UEs_contention = {}\n",
    "        \n",
    "        time_generate_ues_start = time.time()\n",
    "        for i in range(num_UEs): \n",
    "            # TODO: Move the UE creation parameters to the cell above?\n",
    "            UE_temp = UE(i, {1: 0, 2: 1}, UE_arrival[i], UE_serve_mode[i],  num_packets_per_ue, \\\n",
    "                         CWmin=CWmin, CWmax=CWmax)\n",
    "            UE_temp.set_poisson_lambda(lambda_value)\n",
    "            UE_temp.initialize_transmission_record(schedule_contention)\n",
    "            UE_temp.generate_packets(schedule_contention, packet_sizes, priorities) # TODO: Change this\n",
    "            UEs_contention[UE_names[i]] = UE_temp\n",
    "        time_generate_ues_finish = time.time()\n",
    "\n",
    "        \n",
    "\n",
    "        # TODO: Check that the delivery times are always in ascending order\n",
    "        # TODO: check that the arrival times are always in ascending order\n",
    "\n",
    "        # TODO: Make this more general i.e handle packet statuses directly instead of opearting under the \n",
    "        # restrictions of this simulation\n",
    "        print(\"Num packets: \" + str(UEs_contention[\"UE0\"].n_packets))\n",
    "\n",
    "\n",
    "        # Serve the packets with contention\n",
    "        results_iteration = {}\n",
    "        \n",
    "\n",
    "        for i in range(num_iterations_contention[count]):\n",
    "            print(\"Contention iteration: \" + str(i))\n",
    "            time_deep_copy_ues_start = time.time()\n",
    "            UEs_contention_temp = copy.deepcopy(UEs_contention)\n",
    "            time_deep_copy_ues_finish = time.time()\n",
    "\n",
    "            print(\"Generate test network\")\n",
    "            test_network = Network(wifi_slot_time, DIFS, UEs_contention_temp, debug_mode)\n",
    "\n",
    "            time_serve_packets_start = time.time()  \n",
    "            # %lprun -f Network.serve_packets test_network.serve_packets(schedule_contention,\\\n",
    "            #                                     mode_contention, \\\n",
    "            #                                     payload_size = payload_size, \\\n",
    "            #                                     delivery_latency = delivery_latency, \\\n",
    "            #                                     PER = PER, advance_time = advance_time, \\\n",
    "                                                # aggregation_limit = aggregation_limit)\n",
    "            test_network.serve_packets(schedule_contention,\\\n",
    "                                                mode_contention, \\\n",
    "                                                payload_size = payload_size, \\\n",
    "                                                delivery_latency = delivery_latency, \\\n",
    "                                                PER = PER, advance_time = advance_time, \\\n",
    "                                                aggregation_limit = aggregation_limit)\n",
    "            time_serve_packets_finish = time.time()\n",
    "            \n",
    "\n",
    "            print(\"Save UEs_contetion_temp\")\n",
    "            results_iteration[i] = UEs_contention_temp \n",
    "        # for key in results_iteration:\n",
    "        #     print(\"results_iteration \" + str(key), results_iteration[key])\n",
    "\n",
    "        # TODO: Scale to multiple UEs, currently you're extracting the results only for one UE,\n",
    "        # but you should be extracting the results for all UEs\n",
    "        \n",
    "        print(\"Save results_iteration\")\n",
    "        results_per_lambda_per_iteration_contention[num_arrival_iteration] = results_iteration\n",
    "    \n",
    "    print(\"Save results_per_lambda_per_iteration_contention\")\n",
    "    %time results_per_lambda_contention[lambda_value] = results_per_lambda_per_iteration_contention\n",
    "    count = count + 1\n",
    "    \n",
    "\n",
    "execution_finish_time = time.time()\n",
    "execution_duration = execution_finish_time - execution_start_time\n",
    "\n",
    "\n",
    "print(\"Execution duration: \" + str(execution_duration))\n",
    "print(\"Generate ues duration: \" + str(time_generate_ues_finish - time_generate_ues_start))\n",
    "print(\"Serve packets duration: \" + str(time_serve_packets_finish - time_serve_packets_start))\n",
    "print(\"Deep copy ues duration: \" + str(time_deep_copy_ues_finish - time_deep_copy_ues_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ue in UEs_contention_temp:\n",
    "    # print(\"UE: \" + str(ue))\n",
    "    # print(UEs_contention_temp[ue])\n",
    "    for packet in UEs_contention_temp[ue].packets:\n",
    "        if packet.delivery_time is not None:\n",
    "            assert packet.arrival_time < packet.delivery_time\n",
    "\n",
    "y = UEs_contention_temp[\"UE1\"].transmission_record[0][\"queue_information\"][\"queue_lengths\"]\n",
    "x = UEs_contention_temp[\"UE1\"].transmission_record[0][\"queue_information\"][\"queue_times\"]\n",
    "slope, intercept = np.polyfit(x, y, 1)\n",
    "plt.title(\"Queue length vs time\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Queue length\")\n",
    "plt.plot(np.array(x)/10**6, y, label = \"queue information\")\n",
    "plt.plot(np.array(x)/10**6, slope*np.array(x) + intercept, label = \"best fit line\", linewidth = 2)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "print(slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schedule_contention.end_time - 1499491.6)\n",
    "1500010.0 - 1499491.6 + 13*9 - 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a results directory folder using results_directory_simulation and the current time\n",
    "experiment_folder_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "results_directory_experiment = os.path.join(results_directory_simulation, experiment_folder_name)\n",
    "os.makedirs(results_directory_experiment, exist_ok=True)\n",
    "# Plots: CDF of latencies, percentile latency vs lambda, mean latency vs lambda,\n",
    "# number of packets not served vs lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse the results\n",
    "\n",
    "\n",
    "results_allUEs_per_lambda_contention = {}\n",
    "for lambda_value in results_per_lambda_contention:\n",
    "    print(\"\\n\\nlambda value: \", lambda_value)\n",
    "\n",
    "    mean_latencies_across_arrivals = []\n",
    "    percentile_latencies_across_arrivals = []\n",
    "    n_packets_not_served_across_arrivals = []\n",
    "    contention_wins_across_arrivals = []\n",
    "    bus_occupancy_across_arrivals = []\n",
    "    queue_slope_across_arrivals = []\n",
    "\n",
    "    for num_iteration_arrival in results_per_lambda_contention[lambda_value]:\n",
    "        mean_latencies = []\n",
    "        percentile_latencies = []\n",
    "        n_packets_not_served_array = []\n",
    "        contention_wins = []\n",
    "        bus_occupancy = []\n",
    "        queue_slope = []\n",
    "        print(\"arrival iteration \" + str(num_iteration_arrival))\n",
    "        for iteration in results_per_lambda_contention[lambda_value][num_iteration_arrival]:\n",
    "            latencies = []\n",
    "            bus_occupancy_across_ues = []\n",
    "            contention_wins_across_ues = []\n",
    "            queue_slope_across_ues = []\n",
    "            n_packets_not_served = 0\n",
    "            # print(\"iteration\", iteration)\n",
    "            for ue in results_per_lambda_contention[lambda_value][num_iteration_arrival][iteration]:\n",
    "                # print(\"UE: \", ue)\n",
    "                UE_temp = results_per_lambda_contention[lambda_value][num_iteration_arrival][iteration][ue]\n",
    "                latencies_UE = UE_temp.obtain_packet_latency()\n",
    "                latencies_UE = [latency for latency in latencies_UE if latency is not None]\n",
    "                n_packets_not_served += UE_temp.n_packets - len(latencies_UE)\n",
    "                latencies.extend(latencies_UE)\n",
    "                contention_wins_across_ues.append(UE_temp.transmission_record[0][\"num_wins\"])\n",
    "                bus_occupancy_across_ues.append(np.mean(UE_temp.transmission_record[0][\"num_transmissions\"]))\n",
    "\n",
    "                queue_lengths = np.array(UE_temp.transmission_record[0][\"queue_information\"][\"queue_lengths\"])\n",
    "                queue_times = np.array(UE_temp.transmission_record[0][\"queue_information\"][\"queue_times\"])\n",
    "                # TODO: add a scaling factor\n",
    "                # queue_slopes = (queue_lengths[1:] - queue_lengths[:-1])/(queue_times[1:] - queue_times[:-1])\n",
    "                # queue_slope_across_ues.append(np.mean(queue_slopes))\n",
    "                slope, intercept = np.polyfit(queue_times, queue_lengths, 1)\n",
    "                queue_slope_across_ues.append(slope)\n",
    "\n",
    "\n",
    "            print(\"iteration\", iteration)    \n",
    "            mean_latencies.append(np.mean(latencies))\n",
    "            percentile_latencies.append(compute_percentile(latencies, percentile_to_plot))\n",
    "            n_packets_not_served_array.append(n_packets_not_served)\n",
    "            contention_wins.append(np.mean(contention_wins_across_ues))\n",
    "            bus_occupancy.append(np.mean(bus_occupancy_across_ues))\n",
    "            queue_slope.append(np.mean(queue_slope_across_ues))\n",
    "\n",
    "        print(\"Len(mean_latencies)\", len(mean_latencies))\n",
    "        mean_latencies_across_arrivals.append(np.mean(mean_latencies))\n",
    "        percentile_latencies_across_arrivals.append(np.mean(percentile_latencies))\n",
    "        n_packets_not_served_across_arrivals.append(np.mean(n_packets_not_served_array))\n",
    "        contention_wins_across_arrivals.append(np.mean(contention_wins))\n",
    "        bus_occupancy_across_arrivals.append(np.mean(bus_occupancy))\n",
    "        queue_slope_across_arrivals.append(np.mean(queue_slope))\n",
    "\n",
    "    result_temp = {}        \n",
    "    result_temp[\"mean_latency\"] = np.mean(mean_latencies_across_arrivals)\n",
    "    result_temp[\"mean_latency_std\"] = np.std(mean_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency\"] = np.mean(percentile_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency_std\"] = np.std(percentile_latencies_across_arrivals)\n",
    "    result_temp[\"n_packets_not_served\"] = np.mean(n_packets_not_served_across_arrivals)\n",
    "    result_temp[\"n_packets_not_served_std\"] = np.std(n_packets_not_served_across_arrivals)\n",
    "    result_temp[\"contention_wins\"] = np.mean(contention_wins_across_arrivals)\n",
    "    result_temp[\"bus_occupancy\"] = np.mean(bus_occupancy_across_arrivals)\n",
    "    result_temp[\"queue_slope\"] = np.mean(queue_slope_across_arrivals)\n",
    "    results_allUEs_per_lambda_contention[lambda_value] = result_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters and the results of the experiment to a file\n",
    "\n",
    "experiment_parameters = {\n",
    "    \"config_file\": config_file,\n",
    "    \"setting_reserved\": parameters[setting_reserved],\n",
    "    \"setting_contention\": parameters[setting_contention],\n",
    "    \"num_UEs\": num_UEs,\n",
    "    \"num_packets_per_ue\": num_packets_per_ue,\n",
    "    \"packet_sizes\": packet_sizes,\n",
    "    \"priorities\": priorities,\n",
    "    \"UE_arrival\": UE_arrival,\n",
    "    \"UE_serve_mode\": UE_serve_mode,\n",
    "    \"start_offset\": start_offset, # microseconds\n",
    "    \"end_time\": end_time,\n",
    "    \"percentile_to_plot\": percentile_to_plot,\n",
    "    \"wifi_slot_time\": wifi_slot_time,\n",
    "    \"DIFS\": DIFS,\n",
    "    \"num_iterations_contention\": num_iterations_contention,\n",
    "    \"num_iterations_arrival\": num_iterations_arrival,\n",
    "    \"contention_mode\": mode_contention,\n",
    "    \"advance_time\": advance_time,\n",
    "    \"CWmin\": CWmin,\n",
    "    \"CWmax\": CWmax,\n",
    "    \"lambda_range\": lambda_range,\n",
    "    \"execution_duration\": execution_duration\n",
    "}\n",
    "\n",
    "# Write experiment_parameters_json to a json file with filename experiment_parameters.json\n",
    "\n",
    "experiment_parameters_json = json.dumps(experiment_parameters, indent=4, cls=NumpyEncoder)\n",
    "experiment_parameters_json_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                   \"experiment_parameters.json\")\n",
    "with open(experiment_parameters_json_filename, \"w\") as file:\n",
    "    file.write(experiment_parameters_json)\n",
    "\n",
    "latencies = UEs_contention_temp[\"UE0\"].obtain_packet_latency()\n",
    "experiment_parameters_pickle = {\n",
    "    # \"schedule_contention\": schedule_contention,\n",
    "    # \"results_per_lambda_contention\": results_per_lambda_contention,\n",
    "    # \"results_allUEs_per_lambda_reserved\": results_per_lambda_per_iteration_contention,\n",
    "    \"UEs_contention\": latencies,\n",
    "    # \"results_allUEs_per_lambda_contention\": results_allUEs_per_lambda_contention,\n",
    "    # \"experiment_parameters\": experiment_parameters\n",
    "}\n",
    "\n",
    "experiment_parameters_pickle_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                    \"experiment_parameters.pkl\")\n",
    "\n",
    "with open(experiment_parameters_pickle_filename, \"wb\") as file:\n",
    "    pickle.dump(experiment_parameters_pickle, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "lambda_range = lambda_original\n",
    "\n",
    "# lambda_range = lambda_range[:8]\n",
    "\n",
    "scale = \"linear\"\n",
    "percentile_filename = \"percentile_latency_allUEs_all_\" + scale + \".png\"\n",
    "percentile_slope_filename = \"percentile_slope_allUEs_all_\" + scale + \".png\"\n",
    "mean_filename = \"mean_latency_allUEs_all_\" + scale + \".png\"\n",
    "mean_slope_filename = \"mean_slope_allUEs_all_\" + scale + \".png\"\n",
    "n_packets_not_served_filename = \"n_packets_not_served_allUEs_all_\" + scale + \".png\"\n",
    "bus_occupancy_filename = \"bus_occupancy_10UEs_all_extended_\" + scale + \".png\"\n",
    "n_wins_filename = \"n_wins_10UEs_all_extended_\" + scale + \".png\"\n",
    "scaling_factor = 1e6\n",
    "\n",
    "# Plot the percentile curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# percentiles = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     percentiles.append(results_allUEs_per_lambda_reserved[lambda_value][\"percentile_latency\"])\n",
    "# plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time), \\\n",
    "#          percentiles, \".-\", label = \"reserved\")\n",
    "\n",
    "percentiles_contention = []\n",
    "percentiles_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    percentiles_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"percentile_latency\"])\n",
    "    percentiles_contention_std.append(\\\n",
    "        results_allUEs_per_lambda_contention[lambda_value][\"percentile_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*scaling_factor, \\\n",
    "        percentiles_contention, percentiles_contention_std, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(str(percentile_to_plot) + \"percentile latency (us)\")\n",
    "plt.legend()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 {percentile_to_plot} percentile latency vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.text(0, percentiles_contention[0], str(np.round(percentiles_contention[0],2)), \\\n",
    "         fontsize=12, verticalalignment='bottom')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(results_directory_experiment, percentile_filename))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "slope = np.diff(percentiles_contention)/(np.diff(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time))\n",
    "plt.title(\"Percentile latency slope\")\n",
    "plt.xlabel(\"lambda*schedule_duration (us)\")\n",
    "plt.ylabel(str(percentile_to_plot) + \"percentile latency slope (us)\")\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "        plt.ylim(10**-2, 10**2)\n",
    "plt.plot(np.array(lambda_range[1:])*(schedule_contention.end_time - schedule_contention.start_time), slope, \".-\")\n",
    "plt.savefig(os.path.join(results_directory_experiment, percentile_slope_filename))\n",
    "\n",
    "print(slope)\n",
    "# Plot the mean latency curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# mean_latencies = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     mean_latencies.append(results_allUEs_per_lambda_reserved[lambda_value][\"mean_latency\"])\n",
    "# plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time),\\\n",
    "#          mean_latencies, \".-\", label = \"reserved\")\n",
    "\n",
    "\n",
    "\n",
    "mean_latencies_contention = []\n",
    "mean_latencies_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    mean_latencies_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"mean_latency\"])\n",
    "    mean_latencies_contention_std.append(\\\n",
    "        results_allUEs_per_lambda_contention[lambda_value][\"mean_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*scaling_factor,\\\n",
    "        mean_latencies_contention, mean_latencies_contention_std, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "\n",
    "\n",
    "plt.text(0, mean_latencies_contention[0], str(np.round(mean_latencies_contention[0],2)), \\\n",
    "         fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Mean latency (us)\")\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 mean latency vs lambda, \\n PER = {PER}, \\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         )\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(results_directory_experiment, mean_filename))\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "slope = np.diff(mean_latencies_contention)/(np.diff(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time))\n",
    "plt.title(\"Mean latency slope\")\n",
    "plt.xlabel(\"lambda*schedule_duration (us)\")\n",
    "plt.ylabel(\"Mean percentile latency slope (us)\")\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "plt.plot(np.array(lambda_range[1:])*(schedule_contention.end_time - schedule_contention.start_time), slope, \".-\")\n",
    "plt.savefig(os.path.join(results_directory_experiment, mean_slope_filename))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# mean_latencies = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     mean_latencies.append(results_allUEs_per_lambda_reserved[lambda_value][\"mean_latency\"])\n",
    "# plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time),\\\n",
    "#          mean_latencies, \".-\", label = \"reserved\")\n",
    "\n",
    "# scale = \"linear\"\n",
    "\n",
    "\n",
    "unserved_packets_contention = []\n",
    "unserved_packets_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    unserved_packets_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"n_packets_not_served\"])\n",
    "    unserved_packets_contention_std.append(\\\n",
    "        results_allUEs_per_lambda_contention[lambda_value][\"n_packets_not_served_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*scaling_factor,\\\n",
    "        np.array(unserved_packets_contention) + 1, np.array(unserved_packets_contention_std) + 0.001, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "\n",
    "\n",
    "# plt.text(0, unserved_packets_contention[0], str(np.round(unserved_packets_contention[0],2)), \\\n",
    "        #  fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Unserved packets\")\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 unserved vs lambda, \\n PER = {PER}, \\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(results_directory_experiment, n_packets_not_served_filename))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bus_occupancy_contention = []\n",
    "for lambda_value in lambda_range:\n",
    "    bus_occupancy_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"bus_occupancy\"])\n",
    "plt.plot(np.array(lambda_range)*scaling_factor, \\\n",
    "        bus_occupancy_contention, '.-', label = \"contention\")\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Bus occupancy\")\n",
    "plt.legend()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 Bus occupancy vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, bus_occupancy_filename))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "wins_contention = []\n",
    "for lambda_value in lambda_range:\n",
    "    wins_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"contention_wins\"])\n",
    "plt.plot(np.array(lambda_range)*scaling_factor, \\\n",
    "        wins_contention, '.-', label = \"contention\")\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Contention wins\")\n",
    "plt.legend()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 num_wins vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, n_wins_filename))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "queue_slope = []\n",
    "for lambda_value in lambda_range:\n",
    "    queue_slope.append(results_allUEs_per_lambda_contention[lambda_value][\"queue_slope\"])\n",
    "plt.plot(np.array(lambda_range)*scaling_factor, \\\n",
    "        queue_slope, '.-', label = \"contention\")\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"queue slope\")\n",
    "plt.legend()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 queue slope vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, n_wins_filename))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting inter-arrival times and arrival times\n",
    "UE_temp = results_per_lambda_per_iteration_contention[lambda_range[0]][0][\"UEs\"][\"UE0\"]\n",
    "arrival_times = []\n",
    "for packet in UE_temp.packets:\n",
    "    arrival_times.append(packet.arrival_time)\n",
    "\n",
    "# plot histogram of arrival times\n",
    "plt.hist(arrival_times, bins=100)\n",
    "plt.xlabel(\"Arrival time (us)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Arrival time histogram\")\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"arrival_time_histogram.png\"))\n",
    "plt.show()\n",
    "\n",
    "arrival_times = np.array(arrival_times)\n",
    "inter_arrival_times = np.diff(arrival_times)\n",
    "plt.hist(inter_arrival_times, bins=100)\n",
    "plt.xlabel(\"Inter-arrival time (us)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Inter-arrival time histogram\")\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"inter_arrival_time_histogram.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating result extraction into the main body of the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a results directory folder using results_directory_simulation and the current time\n",
    "experiment_folder_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "results_directory_experiment = os.path.join(results_directory_simulation, experiment_folder_name)\n",
    "UEs_directory = os.path.join(results_directory_experiment, \"UEs\")\n",
    "os.makedirs(results_directory_experiment, exist_ok=True)\n",
    "os.makedirs(UEs_directory, exist_ok=True)\n",
    "# Plots: CDF of latencies, percentile latency vs lambda, mean latency vs lambda,\n",
    "# number of packets not served vs lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a schedule, UEs and serve the packets, not integrated with result extraction\n",
    "\n",
    "slots_temp = {}\n",
    "slots_temp[0] = Slot(0, start_offset, end_time, \"contention\", UE_names)\n",
    "schedule_contention = Schedule(start_offset, end_time, 1, slots_temp)\n",
    "\n",
    "\n",
    "# print(schedule_reserved)\n",
    "print(schedule_contention)\n",
    "\n",
    "results_per_lambda_contention = {}\n",
    "\n",
    "count = 0\n",
    "\n",
    "execution_start_time = time.time()\n",
    "\n",
    "\n",
    "results_allUEs_per_lambda_contention = {}\n",
    "\n",
    "for lambda_value in lambda_range:\n",
    "    \n",
    "    print(\"\\n###### Lambda value: \" + str(lambda_value), \", Count: \" + str(count), \"######\")\n",
    "    \n",
    "    mean_latencies_across_arrivals = []\n",
    "    percentile_latencies_across_arrivals = []\n",
    "    n_packets_not_served_across_arrivals = []\n",
    "    contention_wins_across_arrivals = []\n",
    "    bus_occupancy_across_arrivals = []\n",
    "    \n",
    "    results_per_lambda_per_iteration_contention = {}\n",
    "    for num_arrival_iteration in range(num_iterations_arrival):\n",
    "        print(\"\\nArrival iteration: \" + str(num_arrival_iteration))\n",
    "        # Create UEs and packets\n",
    "        \n",
    "        UEs_contention = {}\n",
    "        \n",
    "        \n",
    "        time_generate_ues_start = time.time()\n",
    "        for i in range(num_UEs): \n",
    "            # TODO: Move the UE creation parameters to the cell above?\n",
    "            UE_temp = UE(i, {1: 0, 2: 1}, UE_arrival[i], UE_serve_mode[i],  num_packets_per_ue, \\\n",
    "                         CWmin=CWmin, CWmax=CWmax)\n",
    "            UE_temp.set_poisson_lambda(lambda_value)\n",
    "            UE_temp.initialize_transmission_record(schedule_contention)\n",
    "            UE_temp.generate_packets(schedule_contention, packet_sizes, priorities) # TODO: Change this\n",
    "            UEs_contention[UE_names[i]] = UE_temp\n",
    "        time_generate_ues_finish = time.time()\n",
    "\n",
    "        # TODO: Check that the delivery times are always in ascending order\n",
    "        # TODO: check that the arrival times are always in ascending order\n",
    "\n",
    "        # TODO: Make this more general i.e handle packet statuses directly instead of opearting under the \n",
    "        # restrictions of this simulation\n",
    "        print(\"Num packets: \" + str(UEs_contention[\"UE0\"].n_packets))\n",
    "\n",
    "\n",
    "        # Serve the packets with contention\n",
    "        results_iteration = {}\n",
    "        mean_latencies = []\n",
    "        percentile_latencies = []\n",
    "        n_packets_not_served_array = []\n",
    "        contention_wins = []\n",
    "        bus_occupancy = []\n",
    "\n",
    "        for i in range(num_iterations_contention[count]):\n",
    "            print(\"Contention iteration: \" + str(i))\n",
    "            time_deep_copy_ues_start = time.time()\n",
    "            UEs_contention_temp = copy.deepcopy(UEs_contention)\n",
    "            time_deep_copy_ues_finish = time.time()\n",
    "\n",
    "            print(\"Generate test network\")\n",
    "            test_network = Network(wifi_slot_time, DIFS, UEs_contention_temp, debug_mode)\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "            time_serve_packets_start = time.time()  \n",
    "            # %lprun -f Network.serve_packets test_network.serve_packets(schedule_contention,\\\n",
    "            #                                     mode_contention, \\\n",
    "            #                                     payload_size = payload_size, \\\n",
    "            #                                     delivery_latency = delivery_latency, \\\n",
    "            #                                     PER = PER, advance_time = advance_time)\n",
    "            test_network.serve_packets(schedule_contention,\\\n",
    "                                                mode_contention, \\\n",
    "                                                payload_size = payload_size, \\\n",
    "                                                delivery_latency = delivery_latency, \\\n",
    "                                                PER = PER, advance_time = advance_time)\n",
    "            time_serve_packets_finish = time.time()\n",
    "\n",
    "            latencies = []\n",
    "            bus_occupancy_across_ues = []\n",
    "            contention_wins_across_ues = []\n",
    "            n_packets_not_served = 0\n",
    "\n",
    "\n",
    "            for ue in UEs_contention_temp:\n",
    "                # print(\"UE: \", ue)\n",
    "                UE_temp = UEs_contention_temp[ue]\n",
    "                latencies_UE = UE_temp.obtain_packet_latency()\n",
    "                latencies_UE = [latency for latency in latencies_UE if latency is not None]\n",
    "                n_packets_not_served += UE_temp.n_packets - len(latencies_UE)\n",
    "                latencies.extend(latencies_UE)\n",
    "                contention_wins_across_ues.append(UE_temp.transmission_record[0][\"num_wins\"])\n",
    "                bus_occupancy_across_ues.append(np.mean(UE_temp.transmission_record[0][\"num_transmissions\"]))\n",
    "            \n",
    "            mean_latencies.append(np.mean(latencies))\n",
    "            percentile_latencies.append(compute_percentile(latencies, percentile_to_plot))\n",
    "            n_packets_not_served_array.append(n_packets_not_served)\n",
    "            contention_wins.append(np.mean(contention_wins_across_ues))\n",
    "            bus_occupancy.append(np.mean(bus_occupancy_across_ues))\n",
    "\n",
    "            print(\"Save UEs_contetion_temp\")\n",
    "            # results_iteration[i] = UEs_contention_temp\n",
    "            UEs_filename = os.path.join(UEs_directory, \"UEs_contention_\" + \\\n",
    "                                        str(count) + \"_\" + str(num_arrival_iteration) + \"_\" + \\\n",
    "                                        str(i) + \".pkl\")\n",
    "            with open(UEs_filename, \"wb\") as file:\n",
    "                pickle.dump(UEs_contention_temp, file) \n",
    "        \n",
    "        mean_latencies_across_arrivals.append(np.mean(mean_latencies))\n",
    "        percentile_latencies_across_arrivals.append(np.mean(percentile_latencies))\n",
    "        n_packets_not_served_across_arrivals.append(np.mean(n_packets_not_served_array))\n",
    "        contention_wins_across_arrivals.append(np.mean(contention_wins))\n",
    "        bus_occupancy_across_arrivals.append(np.mean(bus_occupancy))\n",
    "        \n",
    "        # for key in results_iteration:\n",
    "        #     print(\"results_iteration \" + str(key), results_iteration[key])\n",
    "\n",
    "        # TODO: Scale to multiple UEs, currently you're extracting the results only for one UE,\n",
    "        # but you should be extracting the results for all UEs\n",
    "        \n",
    "        print(\"Save results_iteration\")\n",
    "        # results_per_lambda_per_iteration_contention[num_arrival_iteration] = results_iteration\n",
    "    \n",
    "    result_temp = {}        \n",
    "    result_temp[\"mean_latency\"] = np.mean(mean_latencies_across_arrivals)\n",
    "    result_temp[\"mean_latency_std\"] = np.std(mean_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency\"] = np.mean(percentile_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency_std\"] = np.std(percentile_latencies_across_arrivals)\n",
    "    result_temp[\"n_packets_not_served\"] = np.mean(n_packets_not_served_across_arrivals)\n",
    "    result_temp[\"n_packets_not_served_std\"] = np.std(n_packets_not_served_across_arrivals)\n",
    "    result_temp[\"contention_wins\"] = np.mean(contention_wins_across_arrivals)\n",
    "    result_temp[\"bus_occupancy\"] = np.mean(bus_occupancy_across_arrivals)\n",
    "    results_allUEs_per_lambda_contention[lambda_value] = result_temp\n",
    "    \n",
    "    print(\"Save results_per_lambda_per_iteration_contention\")\n",
    "    results_per_lambda_contention[lambda_value] = results_per_lambda_per_iteration_contention\n",
    "    count = count + 1\n",
    "    \n",
    "\n",
    "execution_finish_time = time.time()\n",
    "execution_duration = execution_finish_time - execution_start_time\n",
    "\n",
    "\n",
    "print(\"Execution duration: \" + str(execution_duration))\n",
    "print(\"Generate ues duration: \" + str(time_generate_ues_finish - time_generate_ues_start))\n",
    "print(\"Serve packets duration: \" + str(time_serve_packets_finish - time_serve_packets_start))\n",
    "print(\"Deep copy ues duration: \" + str(time_deep_copy_ues_finish - time_deep_copy_ues_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a results directory folder using results_directory_simulation and the current time\n",
    "# experiment_folder_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "# results_directory_experiment = os.path.join(results_directory_simulation, experiment_folder_name)\n",
    "# os.makedirs(results_directory_experiment, exist_ok=True)\n",
    "# # Plots: CDF of latencies, percentile latency vs lambda, mean latency vs lambda,\n",
    "# # number of packets not served vs lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters and the results of the experiment to a file\n",
    "\n",
    "experiment_parameters = {\n",
    "    \"config_file\": config_file,\n",
    "    \"setting_reserved\": parameters[setting_reserved],\n",
    "    \"setting_contention\": parameters[setting_contention],\n",
    "    \"num_UEs\": num_UEs,\n",
    "    \"num_packets_per_ue\": num_packets_per_ue,\n",
    "    \"packet_sizes\": packet_sizes,\n",
    "    \"priorities\": priorities,\n",
    "    \"UE_arrival\": UE_arrival,\n",
    "    \"UE_serve_mode\": UE_serve_mode,\n",
    "    \"start_offset\": start_offset, # microseconds\n",
    "    \"end_time\": end_time,\n",
    "    \"percentile_to_plot\": percentile_to_plot,\n",
    "    \"wifi_slot_time\": wifi_slot_time,\n",
    "    \"DIFS\": DIFS,\n",
    "    \"num_iterations_contention\": num_iterations_contention,\n",
    "    \"num_iterations_arrival\": num_iterations_arrival,\n",
    "    \"contention_mode\": mode_contention,\n",
    "    \"advance_time\": advance_time,\n",
    "    \"CWmin\": CWmin,\n",
    "    \"CWmax\": CWmax,\n",
    "    \"lambda_range\": lambda_range,\n",
    "    \"execution_duration\": execution_duration\n",
    "}\n",
    "\n",
    "# Write experiment_parameters_json to a json file with filename experiment_parameters.json\n",
    "\n",
    "experiment_parameters_json = json.dumps(experiment_parameters, indent=4, cls=NumpyEncoder)\n",
    "experiment_parameters_json_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                   \"experiment_parameters.json\")\n",
    "with open(experiment_parameters_json_filename, \"w\") as file:\n",
    "    file.write(experiment_parameters_json)\n",
    "\n",
    "latencies = UEs_contention_temp[\"UE0\"].obtain_packet_latency()\n",
    "experiment_parameters_pickle = {\n",
    "    # \"schedule_contention\": schedule_contention,\n",
    "    # \"results_per_lambda_contention\": results_per_lambda_contention,\n",
    "    # \"results_allUEs_per_lambda_reserved\": results_per_lambda_per_iteration_contention,\n",
    "    \"UEs_contention\": mean_latencies_across_arrivals,\n",
    "    # \"results_allUEs_per_lambda_contention\": results_allUEs_per_lambda_contention,\n",
    "    # \"experiment_parameters\": experiment_parameters\n",
    "}\n",
    "\n",
    "experiment_parameters_pickle_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                    \"experiment_parameters.pkl\")\n",
    "\n",
    "with open(experiment_parameters_pickle_filename, \"wb\") as file:\n",
    "    pickle.dump(experiment_parameters_pickle, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "\n",
    "lambda_range = lambda_original\n",
    "\n",
    "# lambda_range = lambda_range[:8]\n",
    "\n",
    "scale = \"linear\"\n",
    "percentile_filename = \"percentile_latency_allUEs_all_\" + scale + \".png\"\n",
    "percentile_slope_filename = \"percentile_slope_allUEs_all_\" + scale + \".png\"\n",
    "mean_filename = \"mean_latency_allUEs_all_\" + scale + \".png\"\n",
    "mean_slope_filename = \"mean_slope_allUEs_all_\" + scale + \".png\"\n",
    "n_packets_not_served_filename = \"n_packets_not_served_allUEs_all_\" + scale + \".png\"\n",
    "bus_occupancy_filename = \"bus_occupancy_10UEs_all_extended_\" + scale + \".png\"\n",
    "n_wins_filename = \"n_wins_10UEs_all_extended_\" + scale + \".png\"\n",
    "scaling_factor = 1e6\n",
    "\n",
    "# Plot the percentile curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# percentiles = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     percentiles.append(results_allUEs_per_lambda_reserved[lambda_value][\"percentile_latency\"])\n",
    "# plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time), \\\n",
    "#          percentiles, \".-\", label = \"reserved\")\n",
    "\n",
    "percentiles_contention = []\n",
    "percentiles_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    percentiles_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"percentile_latency\"])\n",
    "    percentiles_contention_std.append(\\\n",
    "        results_allUEs_per_lambda_contention[lambda_value][\"percentile_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*scaling_factor, \\\n",
    "        percentiles_contention, percentiles_contention_std, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(str(percentile_to_plot) + \"percentile latency (us)\")\n",
    "plt.legend()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 {percentile_to_plot} percentile latency vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.text(0, percentiles_contention[0], str(np.round(percentiles_contention[0],2)), \\\n",
    "         fontsize=12, verticalalignment='bottom')\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(results_directory_experiment, percentile_filename))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "slope = np.diff(percentiles_contention)/(np.diff(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time))\n",
    "plt.title(\"Percentile latency slope\")\n",
    "plt.xlabel(\"lambda*schedule_duration (us)\")\n",
    "plt.ylabel(str(percentile_to_plot) + \"percentile latency slope (us)\")\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "        plt.ylim(10**-2, 10**2)\n",
    "plt.plot(np.array(lambda_range[1:])*(schedule_contention.end_time - schedule_contention.start_time), slope, \".-\")\n",
    "plt.savefig(os.path.join(results_directory_experiment, percentile_slope_filename))\n",
    "\n",
    "print(slope)\n",
    "# Plot the mean latency curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# mean_latencies = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     mean_latencies.append(results_allUEs_per_lambda_reserved[lambda_value][\"mean_latency\"])\n",
    "# plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time),\\\n",
    "#          mean_latencies, \".-\", label = \"reserved\")\n",
    "\n",
    "\n",
    "\n",
    "mean_latencies_contention = []\n",
    "mean_latencies_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    mean_latencies_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"mean_latency\"])\n",
    "    mean_latencies_contention_std.append(\\\n",
    "        results_allUEs_per_lambda_contention[lambda_value][\"mean_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*scaling_factor,\\\n",
    "        mean_latencies_contention, mean_latencies_contention_std, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "\n",
    "\n",
    "plt.text(0, mean_latencies_contention[0], str(np.round(mean_latencies_contention[0],2)), \\\n",
    "         fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Mean latency (us)\")\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 mean latency vs lambda, \\n PER = {PER}, \\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         )\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(results_directory_experiment, mean_filename))\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "slope = np.diff(mean_latencies_contention)/(np.diff(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time))\n",
    "plt.title(\"Mean latency slope\")\n",
    "plt.xlabel(\"lambda*schedule_duration (us)\")\n",
    "plt.ylabel(\"Mean percentile latency slope (us)\")\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "plt.plot(np.array(lambda_range[1:])*(schedule_contention.end_time - schedule_contention.start_time), slope, \".-\")\n",
    "plt.savefig(os.path.join(results_directory_experiment, mean_slope_filename))\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# mean_latencies = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     mean_latencies.append(results_allUEs_per_lambda_reserved[lambda_value][\"mean_latency\"])\n",
    "# plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time),\\\n",
    "#          mean_latencies, \".-\", label = \"reserved\")\n",
    "\n",
    "# scale = \"linear\"\n",
    "\n",
    "\n",
    "unserved_packets_contention = []\n",
    "unserved_packets_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    unserved_packets_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"n_packets_not_served\"])\n",
    "    unserved_packets_contention_std.append(\\\n",
    "        results_allUEs_per_lambda_contention[lambda_value][\"n_packets_not_served_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*scaling_factor,\\\n",
    "        np.array(unserved_packets_contention) + 1, np.array(unserved_packets_contention_std) + 0.001, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "\n",
    "\n",
    "# plt.text(0, unserved_packets_contention[0], str(np.round(unserved_packets_contention[0],2)), \\\n",
    "        #  fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Unserved packets\")\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 unserved vs lambda, \\n PER = {PER}, \\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(os.path.join(results_directory_experiment, n_packets_not_served_filename))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bus_occupancy_contention = []\n",
    "for lambda_value in lambda_range:\n",
    "    bus_occupancy_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"bus_occupancy\"])\n",
    "plt.plot(np.array(lambda_range)*scaling_factor, \\\n",
    "        bus_occupancy_contention, '.-', label = \"contention\")\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Bus occupancy\")\n",
    "plt.legend()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 Bus occupancy vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, bus_occupancy_filename))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "wins_contention = []\n",
    "for lambda_value in lambda_range:\n",
    "    wins_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"contention_wins\"])\n",
    "plt.plot(np.array(lambda_range)*scaling_factor, \\\n",
    "        wins_contention, '.-', label = \"contention\")\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda (packets/s)\")\n",
    "plt.ylabel(\"Contention wins\")\n",
    "plt.legend()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 Bus occupancy vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(results_directory_experiment, n_wins_filename))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3, 4, 5])\n",
    "b = a**2\n",
    "# plt.plot(a, b)\n",
    "plt.plot(60*a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "        3.1622776601683795e-05,\n",
    "        3.568617492834814e-05,\n",
    "        4.027170343254595e-05,\n",
    "        4.5446453720950844e-05,\n",
    "        5.128613839913648e-05,\n",
    "        5.787619883491209e-05,\n",
    "        6.531305526474715e-05,\n",
    "        7.37055175337934e-05,\n",
    "        8.317637711026709e-05,\n",
    "        9.386420366721355e-05,\n",
    "        0.00010592537251772886,\n",
    "        0.00011953635256737177,\n",
    "        0.00013489628825916533,\n",
    "        0.00015222991328804204,\n",
    "        0.00017179083871575877\n",
    "    ])\n",
    "np.log10(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.linspace(-4.5, -3.765, 15))\n",
    "print(np.linspace(-3.74, -3.62, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(-4.5, -3.34, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scientific_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
