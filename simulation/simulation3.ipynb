{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simulating the WTSN setting\n",
    "\n",
    "Authors: Milind Kumar Vaddiraju, ChatGPT, Copilot\n",
    "\"\"\"\n",
    "\n",
    "# Necessary imports\n",
    "import copy\n",
    "from datetime import datetime\n",
    "import json\n",
    "# %matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "from network_classes import *\n",
    "from utils import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters affecting how a packet is served: essentially MCS and latency from the Excel sheet\n",
    "# TODO: integrate MCS usage into the UE instead of having it outside\n",
    "# TODO: Create a simple CSV file of this\n",
    "\n",
    "\n",
    "# TODO: Remove the 67us from this that contains backoff \n",
    "parameters = {\n",
    "    \"setting 0\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 0,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 591.8\n",
    "    },\n",
    "    \"setting 1\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 0,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 964,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 1470.2\n",
    "    },\n",
    "    \"setting 2\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 0,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 2464,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 2953.4\n",
    "    },\n",
    "    \"setting 3\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 534.2\n",
    "    },\n",
    "    \"setting 4\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 964,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 980.6\n",
    "    },\n",
    "    \"setting 5\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 2464,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 1715\n",
    "    },\n",
    "    \"setting 6\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 519.8\n",
    "    },\n",
    "    \"setting 7\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 964,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 807.8\n",
    "    },\n",
    "    \"setting 8\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 2464,\n",
    "        \"aggregation\": 1,\n",
    "        \"delivery_latency\": 1311.8\n",
    "    },\n",
    "    \"setting 9\": {\n",
    "        \"SNR\": 20,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 1,\n",
    "        \"PER\": 0,\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 10,\n",
    "        \"delivery_latency\": 980.6\n",
    "    },\n",
    "    \"setting 10\": {\n",
    "        \"SNR\": 35,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 8,\n",
    "        \"PER\": 0.1170412, # PER corresponding to PSDU size 1000 as aggregation of 10 x 64 = 1000 B\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 10,\n",
    "        \"delivery_latency\": 563 \n",
    "    },\n",
    "    \"setting 11\": {\n",
    "        \"SNR\": 38,\n",
    "        \"Bandwidth\": 20,\n",
    "        \"MCS\": 6,\n",
    "        \"PER\": 0, # PER corresponding to PSDU size 1000 as aggregation of 10 x 64 = 1000 B\n",
    "        \"payload_size\": 64,\n",
    "        \"aggregation\": 10,\n",
    "        \"delivery_latency\": 591.8 \n",
    "    },\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the simulation parameters\n",
    "\n",
    "results_directory_simulation = \"./results/simulation_3/\"\n",
    "\n",
    "setting_reserved = \"setting 11\"\n",
    "setting_contention = \"setting 11\"\n",
    "payload_size = {\"reserved\": parameters[setting_reserved][\"payload_size\"]*parameters[setting_reserved][\"aggregation\"], \n",
    "                \"contention\": parameters[setting_contention][\"payload_size\"]*parameters[setting_contention][\"aggregation\"]}\n",
    "delivery_latency = {\"reserved\": parameters[setting_reserved][\"delivery_latency\"],\n",
    "                    \"contention\": parameters[setting_contention][\"delivery_latency\"]}\n",
    "PER = {\"reserved\":  parameters[setting_reserved][\"PER\"], \n",
    "       \"contention\":  parameters[setting_contention][\"PER\"]}\n",
    "\n",
    "\n",
    "\n",
    "num_UEs = 10\n",
    "UE_names = [\"UE\" + str(i) for i in range(num_UEs)]\n",
    "num_packets_per_ue = None  # Number of packets per UE for the whole period\n",
    "packet_sizes = [parameters[setting_reserved][\"payload_size\"]] # TODO: Both have same packet size, but what if they don't?\n",
    "priorities = [1]\n",
    "# lambda_range = np.logspace(-4.5, -2.3, 10)\n",
    "lambda_range = np.concatenate(np.logspace(-4.5, -3, 10), np.logspace(-3, -2.2, 5))\n",
    "lambda_original = copy.deepcopy(lambda_range)\n",
    "UE_arrival = [\"Poisson\"]*num_UEs\n",
    "UE_serve_mode = [\"Mode 2\"]*num_UEs\n",
    "num_iterations_arrival = 10\n",
    "\n",
    "\n",
    "## Schedule parameters for reserved base schedule\n",
    "num_slots_per_UE = 200\n",
    "num_slots = num_slots_per_UE*num_UEs\n",
    "start_offset = 10 # microseconds\n",
    "end_time = start_offset\n",
    "slot_duration = delivery_latency[\"reserved\"] + 200 # microseconds\n",
    "\n",
    "\n",
    "# Network properties\n",
    "# Obtained from the sheet\n",
    "wifi_slot_time = 9 # microseconds\n",
    "DIFS = 34 # microseconds\n",
    "\n",
    "\n",
    "\n",
    "# Plot information\n",
    "percentile_to_plot = 99\n",
    "num_iterations_contention = 5\n",
    "mode_contention = \"Mode 3\" \n",
    "advance_time = 10 # microseconds\n",
    "debug_mode = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a schedule, UEs and serve the packets\n",
    "\n",
    "\n",
    "# TODO: move the knowledge of how many packets there are to this part of the code\n",
    "# instead of keeping it in the UE class\n",
    "\n",
    "# Create a schedule\n",
    "slots = {}\n",
    "start_time = start_offset\n",
    "for i in range(num_slots):\n",
    "    slots[i] = Slot(i, start_time, start_time + slot_duration, \"reserved\", [UE_names[i%num_UEs]])\n",
    "    start_time += slot_duration\n",
    "schedule_reserved = Schedule(start_offset, start_time, num_slots, slots)\n",
    "\n",
    "end_time = start_time # Due to variable use while saving experiment parameters\n",
    "\n",
    "slots_temp = {}\n",
    "slots_temp[0] = Slot(0, start_offset, end_time, \"contention\", UE_names)\n",
    "schedule_contention = Schedule(start_offset, end_time, 1, slots_temp)\n",
    "\n",
    "\n",
    "# print(schedule_reserved)\n",
    "print(schedule_contention)\n",
    "\n",
    "results_per_lambda = {}\n",
    "results_per_lambda_contention = {}\n",
    "\n",
    "count = 0\n",
    "\n",
    "for lambda_value in lambda_range:\n",
    "    \n",
    "    print(\"\\n###### Lambda value: \" + str(lambda_value), \", Count: \" + str(count), \"######\")\n",
    "    count = count + 1\n",
    "    \n",
    "    result = {}\n",
    "    results_per_lambda_per_iteration_contention = {}\n",
    "    for num_arrival_iteration in range(num_iterations_arrival):\n",
    "        print(\"\\nArrival iteration: \" + str(num_arrival_iteration))\n",
    "        # Create UEs and packets\n",
    "        \n",
    "        UEs = {}\n",
    "            \n",
    "        for i in range(num_UEs): \n",
    "            # TODO: Move the UE creation parameters to the cell above?\n",
    "            UE_temp = UE(i, {1: 0, 2: 1}, UE_arrival[i], UE_serve_mode[i],  num_packets_per_ue)\n",
    "            UE_temp.set_poisson_lambda(lambda_value)\n",
    "            UE_temp.generate_packets(schedule_reserved, packet_sizes, priorities)\n",
    "            UEs[UE_names[i]] = UE_temp\n",
    "        \n",
    "        UEs_contention = copy.deepcopy(UEs)\n",
    "\n",
    "        # for i in UEs:\n",
    "        #     print(UEs[i])\n",
    "\n",
    "        # Serve the packets\n",
    "        # Serving only one UE to reduce time taken to run code\n",
    "        for i in range(num_UEs):\n",
    "            UEs[UE_names[i]].serve_packets(schedule_reserved, \n",
    "                                        payload_size=payload_size[\"reserved\"], \n",
    "                                        delivery_latency=delivery_latency[\"reserved\"],\n",
    "                                        PER=PER[\"reserved\"])\n",
    "\n",
    "        # for i in UEs:\n",
    "        #     print(UEs[i])\n",
    "            \n",
    "\n",
    "        \n",
    "        result[num_arrival_iteration] = UEs\n",
    "        \n",
    "        \n",
    "\n",
    "        # TODO: Check that the delivery times are always in ascending order\n",
    "        # TODO: check that the arrival times are always in ascending order\n",
    "\n",
    "        # TODO: Make this more general i.e handle packet statuses directly instead of opearting under the \n",
    "        # restrictions of this simulation\n",
    "        print(\"Num packets, reserved: \" + str(UEs[\"UE0\"].n_packets))\n",
    "\n",
    "\n",
    "        # Serve the packets with contention\n",
    "        results_iteration = {}\n",
    "        \n",
    "\n",
    "        for i in range(num_iterations_contention):\n",
    "            print(\"Contention iteration: \" + str(i))\n",
    "            UEs_contention_temp = copy.deepcopy(UEs_contention)\n",
    "\n",
    "            test_network = Network(wifi_slot_time, DIFS, UEs_contention_temp, debug_mode)\n",
    "            test_network.serve_packets(schedule_contention, mode_contention, \n",
    "                                        payload_size = payload_size,\n",
    "                                        delivery_latency = delivery_latency,\n",
    "                                        PER = PER,\n",
    "                                        advance_time = advance_time)\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "            results_iteration[i] = UEs_contention_temp \n",
    "        # for key in results_iteration:\n",
    "        #     print(\"results_iteration \" + str(key), results_iteration[key])\n",
    "\n",
    "        # TODO: Scale to multiple UEs, currently you're extracting the results only for one UE,\n",
    "        # but you should be extracting the results for all UEs\n",
    "        \n",
    "\n",
    "        results_per_lambda_per_iteration_contention[num_arrival_iteration] = results_iteration\n",
    "    \n",
    "    results_per_lambda[lambda_value] = result\n",
    "    results_per_lambda_contention[lambda_value] = results_per_lambda_per_iteration_contention\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a results directory folder using results_directory_simulation and the current time\n",
    "experiment_folder_name = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "results_directory_experiment = os.path.join(results_directory_simulation, experiment_folder_name)\n",
    "os.makedirs(results_directory_experiment, exist_ok=True)\n",
    "# Plots: CDF of latencies, percentile latency vs lambda, mean latency vs lambda,\n",
    "# number of packets not served vs lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_allUEs_per_lambda_contention = {}\n",
    "for lambda_value in results_per_lambda_contention:\n",
    "    print(\"lambda value: \", lambda_value)\n",
    "\n",
    "    mean_latencies_across_arrivals = []\n",
    "    percentile_latencies_across_arrivals = []\n",
    "\n",
    "    for num_iteration_arrival in results_per_lambda_contention[lambda_value]:\n",
    "        mean_latencies = []\n",
    "        percentile_latencies = []\n",
    "        print(\"arrival iteration \" + str(num_iteration_arrival) + \"\\n\")\n",
    "        for iteration in results_per_lambda_contention[lambda_value][num_iteration_arrival]:\n",
    "            latencies = []\n",
    "            # print(\"iteration\", iteration)\n",
    "            for ue in results_per_lambda_contention[lambda_value][num_iteration_arrival][iteration]:\n",
    "                # print(\"UE: \", ue)\n",
    "                UE_temp = results_per_lambda_contention[lambda_value][num_iteration_arrival][iteration][ue]\n",
    "                latencies_UE = UE_temp.obtain_packet_latency()\n",
    "                latencies_UE = [latency for latency in latencies_UE if latency is not None]\n",
    "                latencies.extend(latencies_UE)\n",
    "            print(\"iteration\", iteration)    \n",
    "            mean_latencies.append(np.mean(latencies))\n",
    "            percentile_latencies.append(compute_percentile(latencies, percentile_to_plot))\n",
    "        print(\"Len(mean_latencies)\", len(mean_latencies))\n",
    "        mean_latencies_across_arrivals.append(np.mean(mean_latencies))\n",
    "        percentile_latencies_across_arrivals.append(np.mean(percentile_latencies))\n",
    "\n",
    "    result_temp = {}        \n",
    "    result_temp[\"mean_latency\"] = np.mean(mean_latencies_across_arrivals)\n",
    "    result_temp[\"mean_latency_std\"] = np.std(mean_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency\"] = np.mean(percentile_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency_std\"] = np.std(percentile_latencies_across_arrivals)\n",
    "    results_allUEs_per_lambda_contention[lambda_value] = result_temp\n",
    "\n",
    "\n",
    "results_allUEs_per_lambda_reserved = {}\n",
    "for lambda_value in results_per_lambda:\n",
    "    print(\"lambda value: \", lambda_value)\n",
    "\n",
    "    mean_latencies_across_arrivals = []\n",
    "    percentile_latencies_across_arrivals = []\n",
    "\n",
    "    for num_iteration_arrival in results_per_lambda[lambda_value]:\n",
    "        \n",
    "        latencies = []\n",
    "        print(\"arrival iteration\", num_iteration_arrival)\n",
    "        for ue in results_per_lambda[lambda_value][num_iteration_arrival]:\n",
    "            # print(\"UE: \", ue)\n",
    "            UE_temp = results_per_lambda[lambda_value][num_iteration_arrival][ue]\n",
    "            latencies_UE = UE_temp.obtain_packet_latency()\n",
    "            latencies_UE = [latency for latency in latencies_UE if latency is not None]\n",
    "            latencies.extend(latencies_UE)\n",
    "\n",
    "\n",
    "        mean_latencies_across_arrivals.append(np.mean(latencies))\n",
    "        percentile_latencies_across_arrivals.append(compute_percentile(latencies, percentile_to_plot))\n",
    "        print(\"Len(mean_latencies)\", len(mean_latencies_across_arrivals))\n",
    "\n",
    "    print(\"mean_latencies_across_arrivals\", mean_latencies_across_arrivals)\n",
    "\n",
    "    result_temp = {}        \n",
    "    result_temp[\"mean_latency\"] = np.mean(mean_latencies_across_arrivals)\n",
    "    result_temp[\"mean_latency_std\"] = np.std(mean_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency\"] = np.mean(percentile_latencies_across_arrivals)\n",
    "    result_temp[\"percentile_latency_std\"] = np.std(percentile_latencies_across_arrivals)\n",
    "    results_allUEs_per_lambda_reserved[lambda_value] = result_temp\n",
    "\n",
    "# lambda_range = lambda_range[10:]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters and the results of the experiment to a file\n",
    "\n",
    "experiment_parameters = {\n",
    "    \"setting_reserved\": parameters[setting_reserved],\n",
    "    \"setting_contention\": parameters[setting_contention],\n",
    "    \"num_UEs\": num_UEs,\n",
    "    \"num_packets_per_ue\": num_packets_per_ue,\n",
    "    \"packet_sizes\": packet_sizes,\n",
    "    \"priorities\": priorities,\n",
    "    \"UE_arrival\": UE_arrival,\n",
    "    \"UE_serve_mode\": UE_serve_mode,\n",
    "    \"num_slots_per_UE\": num_slots_per_UE,\n",
    "    \"num_slots\": num_slots,\n",
    "    \"start_offset\": start_offset, # microseconds\n",
    "    \"end_time\": end_time,\n",
    "    \"slot_duration\": slot_duration,\n",
    "    \"percentile_to_plot\": percentile_to_plot,\n",
    "    \"wifi_slot_time\": wifi_slot_time,\n",
    "    \"DIFS\": DIFS,\n",
    "    \"num_iterations_contention\": num_iterations_contention,\n",
    "    \"num_iterations_arrival\": num_iterations_arrival,\n",
    "    \"contention_mode\": mode_contention,\n",
    "    \"advance_time\": advance_time,\n",
    "    \"lambda_range\": lambda_range,\n",
    "}\n",
    "\n",
    "# Write experiment_parameters_json to a json file with filename experiment_parameters.json\n",
    "\n",
    "experiment_parameters_json = json.dumps(experiment_parameters, indent=4, cls=NumpyEncoder)\n",
    "experiment_parameters_json_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                   \"experiment_parameters.json\")\n",
    "with open(experiment_parameters_json_filename, \"w\") as file:\n",
    "    file.write(experiment_parameters_json)\n",
    "\n",
    "\n",
    "experiment_parameters_pickle = {\n",
    "    \"schedule_reserved\": schedule_reserved,\n",
    "    \"schedule_contention\": schedule_contention,\n",
    "    \"results_per_lambda\": results_per_lambda,\n",
    "    \"results_per_lambda_contention\": results_per_lambda_contention,\n",
    "    \"results_allUEs_per_lambda_reserved\": results_per_lambda_per_iteration_contention,\n",
    "    \"results_allUEs_per_lambda_contention\": results_allUEs_per_lambda_contention,\n",
    "    \"experiment_parameters\": experiment_parameters\n",
    "}\n",
    "\n",
    "experiment_parameters_pickle_filename = os.path.join(results_directory_experiment, \\\n",
    "                                                    \"experiment_parameters.pkl\")\n",
    "\n",
    "with open(experiment_parameters_pickle_filename, \"wb\") as file:\n",
    "    pickle.dump(experiment_parameters_pickle, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_range = lambda_original\n",
    "\n",
    "lambda_range = lambda_range[:count - 1]\n",
    "\n",
    "scale = \"linear\"\n",
    "\n",
    "# Plot the percentile curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# percentiles = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     percentiles.append(results_allUEs_per_lambda_reserved[lambda_value][\"percentile_latency\"])\n",
    "# plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time), \\\n",
    "#          percentiles, \".-\", label = \"reserved\")\n",
    "\n",
    "\n",
    "percentiles = []\n",
    "percentiles_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    percentiles.append(results_allUEs_per_lambda_reserved[lambda_value][\"percentile_latency\"])\n",
    "    percentiles_std.append(\\\n",
    "        results_allUEs_per_lambda_reserved[lambda_value][\"percentile_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time), \\\n",
    "        percentiles, percentiles_std, label = \"reserved\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "\n",
    "\n",
    "\n",
    "percentiles_contention = []\n",
    "percentiles_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    percentiles_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"percentile_latency\"])\n",
    "    percentiles_contention_std.append(\\\n",
    "        results_allUEs_per_lambda_contention[lambda_value][\"percentile_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time), \\\n",
    "        percentiles_contention, percentiles_contention_std, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "# plt.plot(n_packets_generated, percentiles)\n",
    "plt.xlabel(\"lambda*schedule_duration (us)\")\n",
    "plt.ylabel(str(percentile_to_plot) + \"percentile latency (us)\")\n",
    "plt.legend()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 {percentile_to_plot} percentile latency vs lambda, \\n PER = {PER},\\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \\n\"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\"\n",
    "        )\n",
    "plt.title(title)\n",
    "# Insert a textbox at the lowest y value of the plot and have y axis be the label\n",
    "plt.text(0, percentiles[0], str(np.round(percentiles[0],2)), fontsize=12, verticalalignment='bottom')\n",
    "plt.text(0, percentiles_contention[0], str(np.round(percentiles_contention[0],2)), \\\n",
    "         fontsize=12, verticalalignment='bottom')\n",
    "plt.tight_layout()\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.savefig(os.path.join(results_directory_experiment, \"percentile_latency_allUEs_log.png\"))\n",
    "elif scale == \"linear\":\n",
    "        plt.savefig(os.path.join(results_directory_experiment, \"percentile_latency_allUEs_linear.png\"))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "slope = np.diff(percentiles_contention)/np.diff(lambda_range)\n",
    "plt.yscale('log')\n",
    "plt.plot(np.array(lambda_range[1:])*(schedule_contention.end_time - schedule_contention.start_time), slope)\n",
    "\n",
    "# Plot the mean latency curve\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "# mean_latencies = []\n",
    "# for lambda_value in lambda_range:\n",
    "#     mean_latencies.append(results_allUEs_per_lambda_reserved[lambda_value][\"mean_latency\"])\n",
    "# plt.plot(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time),\\\n",
    "#          mean_latencies, \".-\", label = \"reserved\")\n",
    "\n",
    "mean_latencies = []\n",
    "mean_latencies_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    mean_latencies.append(results_allUEs_per_lambda_reserved[lambda_value][\"mean_latency\"])\n",
    "    mean_latencies_std.append(\\\n",
    "        results_allUEs_per_lambda_reserved[lambda_value][\"mean_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*(schedule_reserved.end_time - schedule_reserved.start_time), \\\n",
    "        mean_latencies, mean_latencies_std, label = \"reserved\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "\n",
    "mean_latencies_contention = []\n",
    "mean_latencies_contention_std = []\n",
    "for lambda_value in lambda_range:\n",
    "    mean_latencies_contention.append(results_allUEs_per_lambda_contention[lambda_value][\"mean_latency\"])\n",
    "    mean_latencies_contention_std.append(\\\n",
    "        results_allUEs_per_lambda_contention[lambda_value][\"mean_latency_std\"])\n",
    "plt.errorbar(np.array(lambda_range)*(schedule_contention.end_time - schedule_contention.start_time),\\\n",
    "        mean_latencies_contention, mean_latencies_contention_std, label = \"contention\", fmt='.-', \\\n",
    "        capsize=3)\n",
    "\n",
    "plt.text(0, mean_latencies[0], str(np.round(mean_latencies[0],2)), fontsize=12, verticalalignment='top')\n",
    "plt.text(0, mean_latencies_contention[0], str(np.round(mean_latencies_contention[0],2)), \\\n",
    "         fontsize=12, verticalalignment='bottom')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"lambda*schedule_duration\")\n",
    "plt.ylabel(\"Mean latency (us)\")\n",
    "\n",
    "if scale == \"log\":\n",
    "        plt.yscale('log')\n",
    "\n",
    "title = (f\"Simulation 3 mean latency vs lambda, \\n PER = {PER}, \\n\"\n",
    "         f\"num_UEs: {num_UEs}, \\n\"\n",
    "         f\"allowed_payload: {payload_size} B, \\n \"\n",
    "         f\"packet size: {packet_sizes[0]} B, \\n\"\n",
    "         f\"delivery_latency: {delivery_latency} us ,\\n\"\n",
    "         f\"num_slots: {num_slots}, \\n\"\n",
    "         f\"slot_duration: {slot_duration} us ,\\n\")\n",
    "plt.title(title)\n",
    "plt.tight_layout()\n",
    "if scale == \"log\":\n",
    "        plt.savefig(os.path.join(results_directory_experiment, \"mean_latency_allUEs_log.png\"))\n",
    "elif scale == \"linear\":\n",
    "        plt.savefig(os.path.join(results_directory_experiment, \"mean_latency_allUEs_linear.png\"))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "slope = np.diff(mean_latencies_contention)/np.diff(lambda_range)\n",
    "plt.yscale('log')\n",
    "plt.plot(np.array(lambda_range[1:])*(schedule_contention.end_time - schedule_contention.start_time), slope)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_self_contention = []\n",
    "\n",
    "for j in range(len(lambda_range)):\n",
    "    self_contention_count = 0\n",
    "    print(\"j\", j)\n",
    "    UE_temp = results_per_lambda_per_iteration_contention[lambda_range[j]][0][\"UE0\"]\n",
    "    # print(UE_temp)\n",
    "    latency_array = UE_temp.obtain_packet_latency()\n",
    "    no_contention_array = []\n",
    "    for i in range(len(latency_array)):\n",
    "        if latency_array[i] == None:\n",
    "            assert UE_temp.packets[i].arrival_time + 591.8 + 34 + 135 >= 791800, \"Failed assertion\" \n",
    "        elif np.floor(latency_array[i]- (591.8 + 34 + 135)) > 0:\n",
    "            # pass\n",
    "            \n",
    "            if not (UE_temp.packets[i].arrival_time >= UE_temp.packets[i-1].arrival_time and \\\n",
    "                UE_temp.packets[i].arrival_time <= UE_temp.packets[i-1].delivery_time):\n",
    "\n",
    "                print(\"i:\", i)\n",
    "                print(np.floor(latency_array[i]) - 591.8 - 34 - 135)\n",
    "                print(UE_temp.packets[i])\n",
    "                print(\"Previous packet\")\n",
    "                print(UE_temp.packets[i-1])\n",
    "            self_contention_count += 1\n",
    "            # assert UE_temp.packets[i].arrival_time >= UE_temp.packets[i-1].arrival_time and \\\n",
    "            #     UE_temp.packets[i].arrival_time <= UE_temp.packets[i-1].delivery_time, \"Failed assertion\"                \n",
    "        else:\n",
    "            no_contention_array.append(latency_array[i])\n",
    "    print(np.mean(no_contention_array))\n",
    "    print(np.mean([latency for latency in latency_array if latency is not None]))\n",
    "    num_self_contention.append(self_contention_count/UE_temp.n_packets)\n",
    "    print(\"self_contention_count\", self_contention_count)   \n",
    "    print(len(latency_array) - len(no_contention_array))\n",
    "\n",
    "plt.plot(lambda_range*(schedule_contention.end_time - schedule_contention.start_time), num_self_contention)\n",
    "plt.xlabel(\"lambda*schedule_duration\")\n",
    "plt.ylabel(\"Fraction of self-contention\")\n",
    "plt.title(\"Fraction of self-contention vs lambda\")\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"self_contention.png\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting inter-arrival times and arrival times\n",
    "UE_temp = results_per_lambda_per_iteration_contention[lambda_range[0]][0][\"UEs\"][\"UE0\"]\n",
    "arrival_times = []\n",
    "for packet in UE_temp.packets:\n",
    "    arrival_times.append(packet.arrival_time)\n",
    "\n",
    "# plot histogram of arrival times\n",
    "plt.hist(arrival_times, bins=100)\n",
    "plt.xlabel(\"Arrival time (us)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Arrival time histogram\")\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"arrival_time_histogram.png\"))\n",
    "plt.show()\n",
    "\n",
    "arrival_times = np.array(arrival_times)\n",
    "inter_arrival_times = np.diff(arrival_times)\n",
    "plt.hist(inter_arrival_times, bins=100)\n",
    "plt.xlabel(\"Inter-arrival time (us)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Inter-arrival time histogram\")\n",
    "plt.savefig(os.path.join(results_directory_experiment, \"inter_arrival_time_histogram.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(end_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in results_per_lambda:\n",
    "    print(\"key\", key)\n",
    "    for key2 in results_per_lambda[key]:\n",
    "        print(\"\\tkey2\", key2)\n",
    "        for key3 in results_per_lambda[key][key2]:\n",
    "            print(\"\\t\\tkey3\", key3)\n",
    "            print(results_per_lambda[key][key2][key3].packets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in results_per_lambda_contention:\n",
    "    print(\"key\", key)\n",
    "    for key2 in results_per_lambda[key]:\n",
    "        print(\"\\tkey2\", key2)\n",
    "        for key3 in results_per_lambda_contention[key][key2]:\n",
    "            print(\"\\t\\tkey3\", key3)\n",
    "            for key4 in results_per_lambda_contention[key][key2][key3]:\n",
    "                print(\"\\t\\t\\tkey4\", key4)\n",
    "            # print(results_per_lambda[key][key2][key3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(2000/(end_time - start_offset))\n",
    "np.log10(1500/(end_time - start_offset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scientific_python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
